[
    {
        "title": "You are where you tweet: a content-based approach to geo-locating twitter users",
        "keywords": [
            "Twitter",
            "location-based estimation",
            "spatial data mining",
            "text mining"
        ],
        "abstract": "We propose and evaluate a probabilistic framework for estimating a Twitter user's city-level location based purely on the content of the user's tweets, even in the absence of any other geospatial cues. By augmenting the massive human-powered sensing capabilities of Twitter and related microblogging services with content-derived location information, this framework can overcome the sparsity of geo-enabled features in these services and enable new location-based personalized information services, the targeting of regional advertisements, and so on. Three of the key features of the proposed approach are: (i) its reliance purely on tweet content, meaning no need for user IP information, private login information, or external knowledge bases; (ii) a classification component for automatically identifying words in tweets with a strong local geo-scope; and (iii) a lattice-based neighborhood smoothing model for refining a user's location estimate. The system estimates k possible locations for each user in descending order of confidence. On average we find that the location estimates converge quickly (needing just 100s of tweets), placing 51% of Twitter users within 100 miles of their actual location.",
        "csoc_result": [
            "geo-spatial",
            "text mining",
            "location based",
            "content-based approach",
            "spatial data",
            "user information",
            "spatial data mining",
            "knowledge base",
            "probabilistic framework",
            "personalized information",
            "cues",
            "personalized service",
            "twitter",
            "estimation method",
            "user location",
            "location information",
            "micro-blog",
            "microblogging",
            "component",
            "sensor networks",
            "data privacy",
            "wireless networks",
            "learning",
            "gis",
            "numerical model",
            "wireless sensor networks",
            "social networks",
            "recommender systems",
            "bayesian networks",
            "content-based",
            "software",
            "personal information",
            "knowledge based systems",
            "ad hoc networks",
            "personalizations",
            "computer vision",
            "text processing",
            "social media",
            "data mining",
            "location based services",
            "telecommunication equipment"
        ],
        "gold_standard": [
            "twitter",
            "spatial data",
            "location based",
            "social media",
            "knowledge base",
            "distribution functions",
            "personalized service",
            "probabilistic framework",
            "geo-spatial",
            "text mining",
            "user information",
            "social networks",
            "estimation method",
            "personal information",
            "content-based approach",
            "text processing",
            "computer science",
            "micro-blog",
            "user location",
            "location information",
            "world wide web",
            "microblogging",
            "data mining",
            "spatial data mining",
            "personalized information",
            "knowledge based systems",
            "personalizations",
            "content-based"
        ],
        "skgc_topics": [
            "twitter",
            "location-based estimation",
            "spatial data mining",
            "text mining",
            "geo-locating",
            "tweets",
            "probabilistic framework",
            "city-level location",
            "content-derived location",
            "microblogging services",
            "regional advertisements",
            "classification component",
            "neighborhood smoothing model",
            "geospatial analysis",
            "user location prediction",
            "social media analytics",
            "location-based services",
            "geographic information systems",
            "tweet analysis",
            "location inference",
            "social sensing",
            "personalized information services",
            "regional targeting",
            "location prediction algorithms"
        ],
        "skgc_topics_ordered": [
            "twitter",
            "spatial data mining",
            "text mining",
            "probabilistic framework",
            "microblogging services",
            "location-based estimation",
            "geo-locating",
            "tweets",
            "city-level location",
            "content-derived location",
            "regional advertisements",
            "classification component",
            "neighborhood smoothing model",
            "geospatial analysis",
            "user location prediction",
            "social media analytics",
            "location-based services",
            "geographic information systems",
            "tweet analysis",
            "location inference",
            "social sensing",
            "personalized information services",
            "regional targeting",
            "location prediction algorithms"
        ],
        "gold_standard_ordered1": [
            "twitter",
            "spatial data mining",
            "text mining",
            "probabilistic framework",
            "microblogging",
            "location based",
            "geo-spatial",
            "user information",
            "content-based approach",
            "social media",
            "estimation method",
            "personal information",
            "content-based",
            "text processing",
            "computer science",
            "micro-blog",
            "user location",
            "location information",
            "world wide web",
            "data mining",
            "personalized information",
            "knowledge based systems",
            "personalizations",
            "distribution functions",
            "personalized service",
            "social networks",
            "knowledge base"
        ],
        "skgc_precision": 0.625,
        "skgc_recall": 0.5555555555555556,
        "skgc_f1": 0.5882352941176471,
        "csoc_topics_ordered": [
            "twitter",
            "spatial data",
            "location based",
            "social media",
            "knowledge base",
            "probabilistic framework",
            "geo-spatial",
            "text mining",
            "user information",
            "social networks",
            "estimation method",
            "personal information",
            "content-based approach",
            "text processing",
            "micro-blog",
            "user location",
            "location information",
            "microblogging",
            "spatial data mining",
            "personalized information",
            "knowledge based systems",
            "personalizations",
            "content-based",
            "personalized service",
            "recommender systems",
            "data mining",
            "numerical model",
            "software",
            "learning",
            "gis",
            "sensor networks",
            "wireless networks",
            "wireless sensor networks",
            "ad hoc networks",
            "computer vision",
            "telecommunication equipment",
            "data privacy",
            "bayesian networks",
            "location based services",
            "component"
        ],
        "gold_standard_ordered2": [
            "twitter",
            "spatial data",
            "location based",
            "social media",
            "knowledge base",
            "probabilistic framework",
            "geo-spatial",
            "text mining",
            "user information",
            "social networks",
            "estimation method",
            "personal information",
            "content-based approach",
            "text processing",
            "micro-blog",
            "user location",
            "location information",
            "microblogging",
            "spatial data mining",
            "personalized information",
            "knowledge based systems",
            "personalizations",
            "content-based",
            "personalized service",
            "distribution functions",
            "computer science",
            "world wide web",
            "data mining",
            "numerical model",
            "ontology",
            "information retrieval",
            "semantic desktop",
            "information management",
            "context-aware recommender systems",
            "recommendation systems",
            "collaborative filtering",
            "matrix factorization"
        ],
        "csoc_precision": 0.625,
        "csoc_recall": 0.6756756756756757,
        "csoc_f1": 0.6493506493506493
    },
    {
        "title": "Automatically refining the wikipedia infobox ontology",
        "keywords": [
            "Semantic Web",
            "Ontology",
            "Wikipedia",
            "Markov Logic Networks"
        ],
        "abstract": "The combined efforts of human volunteers have recently extracted numerous facts from Wikipedia, storing them as machine-harvestable object-attribute-value triples in Wikipedia infoboxes. Machine learning systems, such as Kylin, use these infoboxes as training data, accurately extracting even more semantic knowledge from natural language text. But in order to realize the full power of this information, it must be situated in a cleanly-structured ontology. This paper introduces KOG, an autonomous system for refining Wikipedia's infobox-class ontology towards this end. We cast the problem of ontology refinement as a machine learning problem and solve it using both SVMs and a more powerful joint-inference approach expressed in Markov Logic Networks. We present experiments demonstrating the superiority of the joint-inference approach and evaluating other aspects of our system. Using these techniques, we build a rich ontology, integrating Wikipedia's infobox-class schemata with WordNet. We demonstrate how the resulting ontology may be used to enhance Wikipedia with improved query processing and other features.",
        "csoc_result": [
            "natural languages",
            "wordnet",
            "ontology",
            "markov logic networks",
            "query processing",
            "machine learning",
            "dbpedia",
            "ontology integration",
            "semantics",
            "semantic web",
            "natural language text",
            "first order logic",
            "linguistics",
            "artificial intelligence",
            "search engines",
            "world wide web",
            "markov processes",
            "linked data",
            "query languages",
            "natural language processing",
            "natural language processing systems"
        ],
        "gold_standard": [
            "artificial intelligence",
            "markov logic networks",
            "information retrieval",
            "ontology",
            "ontology integration",
            "semantics",
            "inference",
            "ontology matching",
            "semantic web",
            "natural languages",
            "linked data",
            "natural language text",
            "markov processes",
            "natural language processing systems",
            "natural language processing",
            "world wide web",
            "wordnet",
            "inference engines",
            "machine learning",
            "semantic web technologies"
        ],
        "skgc_topics": [
            "wikipedia",
            "ontology",
            "semantic web",
            "markov logic networks",
            "machine learning",
            "infoboxes",
            "triples",
            "natural language text",
            "svm",
            "joint-inference",
            "wordnet",
            "knowledge extraction",
            "information extraction",
            "data integration",
            "semantic knowledge",
            "ontology refinement",
            "autonomous systems",
            "query processing",
            "machine learning techniques",
            "semantic annotation",
            "structured data",
            "knowledge representation"
        ],
        "skgc_topics_ordered": [
            "ontology",
            "semantic web",
            "markov logic networks",
            "natural language text",
            "wordnet",
            "machine learning",
            "wikipedia",
            "infoboxes",
            "triples",
            "svm",
            "joint-inference",
            "knowledge extraction",
            "information extraction",
            "data integration",
            "semantic knowledge",
            "ontology refinement",
            "autonomous systems",
            "query processing",
            "machine learning techniques",
            "semantic annotation",
            "structured data",
            "knowledge representation"
        ],
        "gold_standard_ordered1": [
            "ontology",
            "semantic web",
            "markov logic networks",
            "natural language text",
            "wordnet",
            "machine learning",
            "artificial intelligence",
            "information retrieval",
            "ontology integration",
            "semantics",
            "inference",
            "ontology matching",
            "semantic web technologies",
            "natural languages",
            "linked data",
            "markov processes",
            "natural language processing systems",
            "natural language processing",
            "world wide web",
            "inference engines"
        ],
        "skgc_precision": 0.45454545454545453,
        "skgc_recall": 0.5,
        "skgc_f1": 0.47619047619047616,
        "csoc_topics_ordered": [
            "wordnet",
            "ontology",
            "markov logic networks",
            "machine learning",
            "ontology integration",
            "semantics",
            "semantic web",
            "natural languages",
            "natural language text",
            "markov processes",
            "natural language processing systems",
            "natural language processing",
            "world wide web",
            "artificial intelligence",
            "query processing",
            "dbpedia",
            "first order logic",
            "linguistics",
            "search engines",
            "linked data",
            "query languages"
        ],
        "gold_standard_ordered2": [
            "wordnet",
            "ontology",
            "markov logic networks",
            "machine learning",
            "ontology integration",
            "semantics",
            "semantic web",
            "natural languages",
            "natural language text",
            "markov processes",
            "natural language processing systems",
            "natural language processing",
            "world wide web",
            "artificial intelligence",
            "inference",
            "ontology matching",
            "information retrieval",
            "inference engines",
            "semantic web technologies",
            "linked data"
        ],
        "csoc_precision": 0.6666666666666666,
        "csoc_recall": 0.7,
        "csoc_f1": 0.6829268292682926
    },
    {
        "title": "Discovering authorities in question answer communities by using link analysis",
        "keywords": [
            "question answer portals",
            "link analysis"
        ],
        "abstract": "Question-Answer portals such as Naver and Yahoo! Answers are quickly becoming rich sources of knowledge on many topics which are not well served by general web search engines. Unfortunately, the quality of the submitted answers is uneven, ranging from excellent detailed answers to snappy and insulting remarks or even advertisements for commercial content. Furthermore, user feedback for many topics is sparse, and can be insufficient to reliably identify good answers from the bad ones. Hence, estimating the authority of users is a crucial task for this emerging domain, with potential applications to answer ranking, spam detection, and incentive mechanism design. We present an analysis of the link structure of a general-purpose question answering community to discover authoritative users, and promising experimental results over a dataset of more than 3 million answers from a popular community QA site. We also describe structural differences between question topics that correlate with the success of link analysis for authority discovery.",
        "csoc_result": [
            "link structure",
            "search engines",
            "web searches",
            "link analysis",
            "web search engines",
            "mechanism design",
            "ranging",
            "question answering",
            "incentive mechanism",
            "spam",
            "range finding",
            "electronic commerce",
            "information retrieval",
            "graph theory",
            "peer-to-peer",
            "natural language processing systems",
            "world wide web",
            "ultra-wideband (uwb)",
            "game theory",
            "online searching",
            "machine design",
            "computational linguistics",
            "data mining",
            "hypertext systems",
            "electronic mail"
        ],
        "gold_standard": [
            "graph theory",
            "link structure",
            "spam",
            "search engines",
            "web searches",
            "online searching",
            "information retrieval",
            "link analysis",
            "web search engines",
            "question answering",
            "information management"
        ],
        "skgc_topics": [
            "question answer portals",
            "link analysis",
            "question answering community",
            "authoritative users",
            "answer ranking",
            "spam detection",
            "incentive mechanism design",
            "link structure",
            "authority discovery",
            "user authority",
            "community QA sites",
            "knowledge extraction",
            "user feedback",
            "answer quality",
            "social networks",
            "information retrieval",
            "data mining",
            "web search engines",
            "online communities"
        ],
        "skgc_topics_ordered": [
            "link analysis",
            "link structure",
            "spam detection",
            "information retrieval",
            "web search engines",
            "question answering community",
            "question answer portals",
            "authoritative users",
            "answer ranking",
            "incentive mechanism design",
            "authority discovery",
            "user authority",
            "community QA sites",
            "knowledge extraction",
            "user feedback",
            "answer quality",
            "social networks",
            "data mining",
            "online communities"
        ],
        "gold_standard_ordered1": [
            "link analysis",
            "link structure",
            "spam",
            "information retrieval",
            "web search engines",
            "question answering",
            "graph theory",
            "search engines",
            "web searches",
            "online searching",
            "information management"
        ],
        "skgc_precision": 0.42105263157894735,
        "skgc_recall": 0.7272727272727273,
        "skgc_f1": 0.5333333333333333,
        "csoc_topics_ordered": [
            "link structure",
            "search engines",
            "web searches",
            "link analysis",
            "web search engines",
            "spam",
            "graph theory",
            "information retrieval",
            "question answering",
            "online searching",
            "mechanism design",
            "incentive mechanism",
            "ranging",
            "range finding",
            "electronic commerce",
            "peer-to-peer",
            "natural language processing systems",
            "world wide web",
            "ultra-wideband (uwb)",
            "game theory",
            "machine design",
            "computational linguistics",
            "data mining",
            "hypertext systems",
            "electronic mail"
        ],
        "gold_standard_ordered2": [
            "link structure",
            "search engines",
            "web searches",
            "link analysis",
            "web search engines",
            "spam",
            "graph theory",
            "information retrieval",
            "question answering",
            "online searching",
            "information management"
        ],
        "csoc_precision": 0.44,
        "csoc_recall": 1.0,
        "csoc_f1": 0.6111111111111112
    },
    {
        "title": "A new approach to cross-modal multimedia retrieval",
        "keywords": [
            "Cross-media",
            "cross-modal",
            "retrieval",
            "document processing",
            "image and text",
            "multimedia"
        ],
        "abstract": "The problem of joint modeling the text and image components of multimedia documents is studied. The text component is represented as a sample from a hidden topic model, learned with latent Dirichlet allocation, and images are represented as bags of visual (SIFT) features. Two hypotheses are investigated: that 1) there is a benefit to explicitly modeling correlations between the two components, and 2) this modeling is more effective in feature spaces with higher levels of abstraction. Correlations between the two components are learned with canonical correlation analysis. Abstraction is achieved by representing text and images at a more general, semantic level. The two hypotheses are studied in the context of the task of cross-modal document retrieval. This includes retrieving the text that most closely matches a query image, or retrieving the images that most closely match a query text. It is shown that accounting for cross-modal correlations and semantic abstraction both improve retrieval accuracy. The cross-modal model is also shown to outperform state-of-the-art image retrieval systems on a unimodal retrieval task.",
        "csoc_result": [
            "content-based image retrieval",
            "digital image",
            "image retrieval systems",
            "query images",
            "electronic document",
            "retrieval algorithms",
            "feature space",
            "correlation coefficient",
            "component",
            "text document",
            "correlation analysis",
            "multimedia contents",
            "semantic levels",
            "color images",
            "content based retrieval",
            "sift",
            "image retrieval",
            "multimedia documents",
            "reference image",
            "retrieval performance",
            "document-processing",
            "semantics",
            "object recognition",
            "classification methods",
            "image enhancement",
            "information retrieval",
            "image quality",
            "multimedia services",
            "character recognition",
            "multimedia systems",
            "ontology",
            "pattern recognition",
            "word processing",
            "image processing",
            "text mining",
            "image analysis",
            "mathematics",
            "image segmentation",
            "software",
            "image matching",
            "database systems",
            "information theory",
            "information retrieval systems",
            "color image processing"
        ],
        "gold_standard": [
            "image retrieval",
            "information retrieval",
            "image retrieval systems",
            "pattern recognition",
            "image matching",
            "retrieval performance",
            "image analysis",
            "semantics",
            "text mining",
            "feature space",
            "multimedia documents",
            "color image processing",
            "digital image",
            "image processing",
            "electronic document",
            "correlation analysis",
            "sift",
            "computer science",
            "semantic levels",
            "content-based image retrieval",
            "information retrieval systems",
            "retrieval algorithms",
            "multimedia contents",
            "query images",
            "classification methods",
            "document-processing",
            "reference image",
            "content based retrieval",
            "object recognition",
            "image segmentation"
        ],
        "skgc_topics": [
            "cross-modal",
            "multimedia retrieval",
            "document processing",
            "image and text",
            "hidden topic model",
            "latent Dirichlet allocation",
            "visual features",
            "canonical correlation analysis",
            "semantic level",
            "retrieval accuracy",
            "cross-media retrieval",
            "multimodal retrieval",
            "semantic analysis",
            "topic modeling",
            "image retrieval",
            "text retrieval",
            "feature extraction",
            "semantic correlation",
            "information retrieval",
            "cross-modal document retrieval"
        ],
        "skgc_topics_ordered": [
            "image retrieval",
            "information retrieval",
            "document processing",
            "canonical correlation analysis",
            "semantic level",
            "retrieval accuracy",
            "feature extraction",
            "cross-modal",
            "multimedia retrieval",
            "image and text",
            "hidden topic model",
            "latent Dirichlet allocation",
            "visual features",
            "cross-media retrieval",
            "multimodal retrieval",
            "semantic analysis",
            "topic modeling",
            "text retrieval",
            "semantic correlation",
            "cross-modal document retrieval"
        ],
        "gold_standard_ordered1": [
            "image retrieval",
            "information retrieval",
            "document-processing",
            "correlation analysis",
            "semantic levels",
            "retrieval performance",
            "feature space",
            "cross-modal",
            "multimedia documents",
            "image and text",
            "hidden topic model",
            "latent Dirichlet allocation",
            "sift",
            "cross-media retrieval",
            "multimodal retrieval",
            "semantics",
            "text mining",
            "pattern recognition",
            "semantic correlation",
            "cross-modal document retrieval",
            "image retrieval systems",
            "image matching",
            "image analysis",
            "color image processing",
            "digital image",
            "image processing",
            "electronic document",
            "computer science",
            "content-based image retrieval",
            "information retrieval systems",
            "retrieval algorithms",
            "multimedia contents",
            "query images",
            "classification methods",
            "reference image",
            "content based retrieval",
            "object recognition",
            "image segmentation"
        ],
        "skgc_precision": 1.0,
        "skgc_recall": 0.5263157894736842,
        "skgc_f1": 0.6896551724137931,
        "csoc_topics_ordered": [
            "image retrieval",
            "information retrieval",
            "image retrieval systems",
            "pattern recognition",
            "image matching",
            "retrieval performance",
            "image analysis",
            "semantics",
            "text mining",
            "feature space",
            "multimedia documents",
            "color image processing",
            "digital image",
            "image processing",
            "electronic document",
            "correlation analysis",
            "sift",
            "semantic levels",
            "content-based image retrieval",
            "information retrieval systems",
            "retrieval algorithms",
            "multimedia contents",
            "query images",
            "classification methods",
            "document-processing",
            "reference image",
            "content based retrieval",
            "object recognition",
            "image segmentation",
            "content-based image retrieval",
            "digital image",
            "query images",
            "electronic document",
            "retrieval algorithms",
            "feature space",
            "correlation coefficient",
            "component",
            "text document",
            "correlation analysis",
            "multimedia contents",
            "semantic levels",
            "color images",
            "content based retrieval",
            "sift",
            "image retrieval",
            "multimedia documents",
            "reference image",
            "retrieval performance",
            "document-processing",
            "semantics",
            "object recognition",
            "classification methods",
            "image enhancement",
            "information retrieval",
            "image quality",
            "multimedia services",
            "character recognition",
            "multimedia systems",
            "ontology",
            "pattern recognition",
            "word processing",
            "image processing",
            "text mining",
            "image analysis",
            "mathematics",
            "image segmentation",
            "software",
            "image matching",
            "database systems",
            "information theory",
            "information retrieval systems",
            "color image processing"
        ],
        "gold_standard_ordered2": [
            "image retrieval",
            "information retrieval",
            "image retrieval systems",
            "pattern recognition",
            "image matching",
            "retrieval performance",
            "image analysis",
            "semantics",
            "text mining",
            "feature space",
            "multimedia documents",
            "color image processing",
            "digital image",
            "image processing",
            "electronic document",
            "correlation analysis",
            "sift",
            "semantic levels",
            "content-based image retrieval",
            "information retrieval systems",
            "retrieval algorithms",
            "multimedia contents",
            "query images",
            "classification methods",
            "document-processing",
            "reference image",
            "content based retrieval",
            "object recognition",
            "image segmentation",
            "computer science"
        ],
        "csoc_precision": 0.4166666666666667,
        "csoc_recall": 1.0,
        "csoc_f1": 0.5882352941176471
    },
    {
        "title": "Towards LarKC: A Platform for Web-Scale Reasoning",
        "keywords": [
            "distributed processing",
            "inference mechanisms",
            "semantic Web"
        ],
        "abstract": "Current semantic Web reasoning systems do not scale to the requirements of their hottest applications, such as analyzing data from millions of mobile devices, dealing with terabytes of scientific data, and content management in enterprises with thousands of knowledge workers. In this paper, we present our plan of building the large knowledge collider, a platform for massive distributed incomplete reasoning that will remove these scalability barriers. This is achieved by (i) enriching the current logic-based semantic Web reasoning methods, (ii) employing cognitively inspired approaches and techniques, and (iii) building a distributed reasoning platform and realizing it both on a high-performance computing cluster and via \"computing at home\". In this paper, we will discuss how the technologies of LarKC would move beyond the state-of-the-art of Web scale reasoning.",
        "csoc_result": [
            "content management",
            "mobile devices",
            "reasoning",
            "inference",
            "computing clusters",
            "context management",
            "scientific data",
            "distributed processing",
            "semantic web",
            "information management",
            "semantics",
            "metadata",
            "world wide web",
            "pervasive computing",
            "knowledge engineering",
            "data visualization",
            "inference engines",
            "formal languages",
            "cluster computing",
            "distributed parameter networks",
            "mobile computing",
            "ontology",
            "context aware applications"
        ],
        "gold_standard": [
            "data integration",
            "reasoning",
            "information management",
            "semantics",
            "context management",
            "inference",
            "mobile devices",
            "semantic web",
            "web servers",
            "knowledge engineering",
            "content management",
            "scientific data",
            "distributed processing",
            "world wide web",
            "inference engines",
            "metadata",
            "data handling"
        ],
        "skgc_topics": [
            "distributed processing",
            "inference mechanisms",
            "semantic Web",
            "web-scale reasoning",
            "large knowledge collider",
            "distributed reasoning",
            "scalability",
            "high-performance computing",
            "computing at home",
            "semantic reasoning",
            "knowledge management",
            "cognitive computing",
            "distributed systems",
            "large-scale data analysis",
            "mobile data analysis",
            "scientific data management",
            "enterprise content management",
            "logic-based reasoning",
            "cognitive approaches",
            "high-performance clusters",
            "distributed computing platforms"
        ],
        "skgc_topics_ordered": [
            "distributed processing",
            "inference mechanisms",
            "semantic Web",
            "distributed reasoning",
            "scalability",
            "high-performance computing",
            "computing at home",
            "knowledge management",
            "cognitive computing",
            "distributed systems",
            "large-scale data analysis",
            "mobile data analysis",
            "scientific data management",
            "enterprise content management",
            "logic-based reasoning",
            "cognitive approaches",
            "high-performance clusters",
            "distributed computing platforms",
            "web-scale reasoning",
            "large knowledge collider",
            "semantic reasoning"
        ],
        "gold_standard_ordered1": [
            "distributed processing",
            "inference",
            "semantic web",
            "content management",
            "scientific data",
            "mobile devices",
            "information management",
            "data integration",
            "reasoning",
            "semantics",
            "context management",
            "web servers",
            "knowledge engineering",
            "world wide web",
            "inference engines",
            "metadata",
            "data handling"
        ],
        "skgc_precision": 0.47619047619047616,
        "skgc_recall": 0.5882352941176471,
        "skgc_f1": 0.5263157894736842,
        "csoc_topics_ordered": [
            "reasoning",
            "inference",
            "content management",
            "mobile devices",
            "context management",
            "scientific data",
            "distributed processing",
            "semantic web",
            "information management",
            "semantics",
            "metadata",
            "world wide web",
            "knowledge engineering",
            "inference engines",
            "computing clusters",
            "pervasive computing",
            "data visualization",
            "formal languages",
            "cluster computing",
            "distributed parameter networks",
            "mobile computing",
            "ontology",
            "context aware applications"
        ],
        "gold_standard_ordered2": [
            "reasoning",
            "inference",
            "content management",
            "mobile devices",
            "context management",
            "scientific data",
            "distributed processing",
            "semantic web",
            "information management",
            "semantics",
            "metadata",
            "world wide web",
            "knowledge engineering",
            "inference engines",
            "data integration",
            "web servers",
            "data handling"
        ],
        "csoc_precision": 0.6086956521739131,
        "csoc_recall": 0.8235294117647058,
        "csoc_f1": 0.7
    },
    {
        "title": "EP-SPARQL: a unified language for event processing and stream reasoning",
        "keywords": [
            "ETALIS",
            "Complex Event Processing",
            "Semantic Web",
            "Rule Systems",
            "Streams"
        ],
        "abstract": "Streams of events appear increasingly today in various Web applications such as blogs, feeds, sensor data streams, geospatial information, on-line financial data, etc. Event Processing (EP) is concerned with timely detection of compound events within streams of simple events. State-of-the-art EP provides on-the-fly analysis of event streams, but cannot combine streams with  background knowledge  and cannot perform  reasoning  tasks. On the other hand, semantic tools can effectively handle background knowledge and perform reasoning thereon, but cannot deal with rapidly changing data provided by event streams.   To bridge the gap, we propose  Event Processing SPARQL (EP-SPARQL)  as a new language for complex events and Stream Reasoning. We provide syntax and formal semantics of the language and devise an effective execution model for the proposed formalism. The execution model is grounded on logic programming, and features effective event processing and inferencing capabilities over temporal and static knowledge. We provide an open-source prototype implementation and present a set of tests to show the usefulness and effectiveness of our approach.",
        "csoc_result": [
            "geo-spatial",
            "formal semantics",
            "data stream",
            "blogs",
            "semantics",
            "logic programming",
            "reasoning",
            "sparql",
            "geospatial information",
            "multiple data streams",
            "semantic web",
            "web application",
            "background knowledge",
            "stream data",
            "sensor data",
            "languages",
            "computer programming languages",
            "formal methods",
            "linguistics",
            "gis",
            "geo-spatial data",
            "formal languages",
            "object oriented programming",
            "sensors",
            "data communication systems",
            "formal logic",
            "ontology",
            "world wide web",
            "query processing",
            "knowledge representation",
            "data mining",
            "query languages",
            "resource description framework",
            "database systems"
        ],
        "gold_standard": [
            "query processing",
            "semantics",
            "sparql",
            "world wide web",
            "knowledge representation",
            "rdf",
            "resource description framework",
            "rdf data",
            "semantic web",
            "logic programming",
            "multiple data streams",
            "reasoning",
            "stream data"
        ],
        "skgc_topics": [
            "event processing",
            "stream reasoning",
            "EP-SPARQL",
            "streams",
            "semantic web",
            "complex event processing",
            "reasoning",
            "logic programming",
            "temporal knowledge",
            "static knowledge",
            "event streams",
            "event detection",
            "real-time data processing",
            "stream data processing",
            "semantic reasoning",
            "rule-based systems",
            "data integration",
            "knowledge representation",
            "inferencing",
            "event-driven architecture"
        ],
        "skgc_topics_ordered": [
            "semantic web",
            "logic programming",
            "reasoning",
            "knowledge representation",
            "stream data processing",
            "stream reasoning",
            "event processing",
            "streams",
            "complex event processing",
            "EP-SPARQL",
            "temporal knowledge",
            "static knowledge",
            "event streams",
            "event detection",
            "real-time data processing",
            "semantic reasoning",
            "rule-based systems",
            "data integration",
            "inferencing",
            "event-driven architecture"
        ],
        "gold_standard_ordered1": [
            "semantic web",
            "logic programming",
            "reasoning",
            "knowledge representation",
            "stream data",
            "query processing",
            "semantics",
            "sparql",
            "world wide web",
            "rdf",
            "resource description framework",
            "rdf data",
            "multiple data streams"
        ],
        "skgc_precision": 0.35,
        "skgc_recall": 0.5384615384615384,
        "skgc_f1": 0.4242424242424242,
        "csoc_topics_ordered": [
            "query processing",
            "semantics",
            "sparql",
            "world wide web",
            "knowledge representation",
            "resource description framework",
            "semantic web",
            "logic programming",
            "multiple data streams",
            "reasoning",
            "stream data",
            "formal semantics",
            "data stream",
            "geo-spatial",
            "geospatial information",
            "background knowledge",
            "sensor data",
            "languages",
            "computer programming languages",
            "formal methods",
            "linguistics",
            "gis",
            "geo-spatial data",
            "formal languages",
            "object oriented programming",
            "sensors",
            "data communication systems",
            "formal logic",
            "ontology",
            "web application",
            "blogs",
            "data mining",
            "query languages",
            "database systems"
        ],
        "gold_standard_ordered2": [
            "query processing",
            "semantics",
            "sparql",
            "world wide web",
            "knowledge representation",
            "resource description framework",
            "semantic web",
            "logic programming",
            "multiple data streams",
            "reasoning",
            "stream data",
            "rdf",
            "rdf data"
        ],
        "csoc_precision": 0.3235294117647059,
        "csoc_recall": 0.8461538461538461,
        "csoc_f1": 0.46808510638297873
    },
    {
        "title": "Rapid prototyping of semantic mash-ups through semantic web pipes",
        "keywords": [
            "mash up",
            "semantic web",
            "pipes",
            "rdf"
        ],
        "abstract": "The use of RDF data published on the Web for applications is still a cumbersome and resource-intensive task due to the limited software support and the lack of standard programming paradigms to deal with everyday problems such as combination of RDF data from dierent sources, object identifier consolidation, ontology alignment and mediation, or plain querying and filtering tasks. In this paper we present a framework, Semantic Web Pipes, that supports fast implementation of Semantic data mash-ups while preserving desirable properties such as abstraction, encapsulation, component-orientation, code re-usability and maintainability which are common and well supported in other application areas.",
        "csoc_result": [
            "ontology matching",
            "programming languages",
            "semantic data",
            "rdf data",
            "semantic information",
            "software",
            "web application",
            "resource description framework",
            "rapid prototyping",
            "rdf",
            "semantics",
            "semantic web",
            "computer programming languages",
            "linguistics",
            "query processing",
            "computer science",
            "world wide web",
            "computer aided design",
            "ontology"
        ],
        "gold_standard": [
            "semantics",
            "world wide web",
            "semantic information",
            "semantic data",
            "computer science",
            "ontology matching",
            "resource description framework",
            "rdf data",
            "semantic web",
            "rdf"
        ],
        "skgc_topics": [
            "semantic mash-ups",
            "semantic web",
            "rdf",
            "ontology alignment",
            "object identifier consolidation",
            "querying",
            "filtering",
            "encapsulation",
            "component-orientation",
            "code re-usability",
            "maintainability",
            "semantic data integration",
            "data mash-ups",
            "semantic technologies",
            "web data processing",
            "rdf data management",
            "ontology mediation",
            "semantic frameworks",
            "data abstraction",
            "semantic data querying",
            "semantic data filtering",
            "semantic web services",
            "data interoperability",
            "semantic web applications"
        ],
        "skgc_topics_ordered": [
            "rdf",
            "semantic web",
            "semantic mash-ups",
            "ontology alignment",
            "object identifier consolidation",
            "querying",
            "filtering",
            "encapsulation",
            "component-orientation",
            "code re-usability",
            "maintainability",
            "semantic data integration",
            "data mash-ups",
            "semantic technologies",
            "web data processing",
            "rdf data management",
            "ontology mediation",
            "semantic frameworks",
            "data abstraction",
            "semantic data querying",
            "semantic data filtering",
            "semantic web services",
            "data interoperability",
            "semantic web applications"
        ],
        "gold_standard_ordered1": [
            "rdf",
            "semantic web",
            "semantics",
            "world wide web",
            "semantic information",
            "semantic data",
            "computer science",
            "ontology matching",
            "resource description framework",
            "rdf data"
        ],
        "skgc_precision": 0.25,
        "skgc_recall": 0.6,
        "skgc_f1": 0.35294117647058826,
        "csoc_topics_ordered": [
            "semantics",
            "world wide web",
            "semantic information",
            "semantic data",
            "computer science",
            "ontology matching",
            "resource description framework",
            "rdf data",
            "semantic web",
            "rdf",
            "programming languages",
            "software",
            "web application",
            "rapid prototyping",
            "computer programming languages",
            "linguistics",
            "query processing",
            "computer aided design",
            "ontology"
        ],
        "gold_standard_ordered2": [
            "semantics",
            "world wide web",
            "semantic information",
            "semantic data",
            "computer science",
            "ontology matching",
            "resource description framework",
            "rdf data",
            "semantic web",
            "rdf"
        ],
        "csoc_precision": 0.5263157894736842,
        "csoc_recall": 1.0,
        "csoc_f1": 0.6896551724137931
    },
    {
        "title": "IM2GPS: estimating geographic information from a single image",
        "keywords": [
            "computer vision",
            "geography",
            "image matching",
            "statistical distributions"
        ],
        "abstract": "Estimating geographic information from an image is an excellent, difficult high-level computer vision problem whose time has come. The emergence of vast amounts of geographically-calibrated image data is a great reason for computer vision to start looking globally - on the scale of the entire planet! In this paper, we propose a simple algorithm for estimating a distribution over geographic locations from a single image using a purely data-driven scene matching approach. For this task, we leverage a dataset of over 6 million GPS-tagged images from the Internet. We represent the estimated image location as a probability distribution over the Earthpsilas surface. We quantitatively evaluate our approach in several geolocation tasks and demonstrate encouraging performance (up to 30 times better than chance). We show that geolocation estimates can provide the basis for numerous other image understanding tasks such as population density estimation, land cover estimation or urban/rural classification.",
        "csoc_result": [
            "reference image",
            "internet",
            "computer vision",
            "single images",
            "gps",
            "image matching",
            "image understanding",
            "probability distributions",
            "image processing",
            "image segmentation",
            "software",
            "probability",
            "computer science",
            "image reconstruction",
            "image quality",
            "face recognition",
            "object recognition"
        ],
        "gold_standard": [
            "image processing",
            "computer vision",
            "probability distribution function",
            "probability distributions",
            "computer science",
            "image matching",
            "single images",
            "object recognition",
            "image understanding"
        ],
        "skgc_topics": [
            "geographic information",
            "computer vision",
            "image matching",
            "statistical distributions",
            "geolocation",
            "GPS-tagged images",
            "probability distribution",
            "scene matching",
            "population density estimation",
            "land cover estimation",
            "urban/rural classification",
            "image analysis",
            "geographic information systems",
            "remote sensing",
            "spatial analysis",
            "geospatial data",
            "image recognition",
            "data-driven methods",
            "scene recognition",
            "geographic estimation",
            "image-based geolocation"
        ],
        "skgc_topics_ordered": [
            "computer vision",
            "image matching",
            "probability distribution",
            "geographic information",
            "geolocation",
            "GPS-tagged images",
            "scene matching",
            "population density estimation",
            "land cover estimation",
            "urban/rural classification",
            "image analysis",
            "geographic information systems",
            "remote sensing",
            "spatial analysis",
            "geospatial data",
            "image recognition",
            "data-driven methods",
            "scene recognition",
            "geographic estimation",
            "image-based geolocation",
            "statistical distributions"
        ],
        "gold_standard_ordered1": [
            "computer vision",
            "image matching",
            "probability distributions",
            "image processing",
            "probability distribution function",
            "computer science",
            "single images",
            "object recognition",
            "image understanding\n\"\"\""
        ],
        "skgc_precision": 0.14285714285714285,
        "skgc_recall": 0.3333333333333333,
        "skgc_f1": 0.2,
        "csoc_topics_ordered": [
            "computer vision",
            "image matching",
            "probability distributions",
            "single images",
            "object recognition",
            "image understanding",
            "image processing",
            "probability",
            "computer science",
            "reference image",
            "internet",
            "gps",
            "image segmentation",
            "software",
            "image reconstruction",
            "image quality",
            "face recognition"
        ],
        "gold_standard_ordered2": [
            "computer vision",
            "image matching",
            "probability distributions",
            "single images",
            "object recognition",
            "image understanding",
            "image processing",
            "probability distribution function",
            "computer science\n\"\"\""
        ],
        "csoc_precision": 0.5294117647058824,
        "csoc_recall": 1.0,
        "csoc_f1": 0.6923076923076924
    },
    {
        "title": "A Systematic Approach to Domain-Specific Language Design Using UML",
        "keywords": [
            "unified modeling language"
        ],
        "abstract": "UML includes special extensibility mechanisms, which are used to define domain-specific modeling languages that are based on UML. These mechanisms have been significantly improved in the latest versions of UML. Unfortunately, there is currently a dearth of published material on how to best exploit these capabilities and, consequently, many UML profiles are either invalid or of poor quality. In this paper, we first provide an overview of the new extensibility mechanisms of UML 2.1 and then describe a method for defining profiles that greatly increases the likelihood of producing technically correct quality UML profiles",
        "csoc_result": [
            "unified modeling language",
            "uml diagrams",
            "modeling languages",
            "domain specific modeling",
            "language design",
            "uml profiles",
            "languages",
            "computer programming languages",
            "model-driven engineering",
            "linguistics",
            "computer systems programming",
            "computational linguistics",
            "graphic methods",
            "program compilers",
            "query languages",
            "object oriented programming",
            "real time systems",
            "software engineering",
            "semantics"
        ],
        "gold_standard": [
            "computer systems programming",
            "object oriented programming",
            "model to model transformation",
            "domain specific modeling",
            "modeling languages",
            "software engineering",
            "uml profiles",
            "model-driven engineering",
            "component-based software architecture",
            "uml diagrams",
            "software architecture",
            "computer programming languages",
            "unified modeling language"
        ],
        "skgc_topics": [
            "unified modeling language",
            "domain-specific modeling languages",
            "UML",
            "extensibility mechanisms",
            "UML profiles",
            "domain-specific languages",
            "modeling techniques",
            "software engineering",
            "UML 2.1",
            "software design",
            "model-driven development",
            "software modeling",
            "UML extensions",
            "profile definition",
            "software quality",
            "technical correctness"
        ],
        "skgc_topics_ordered": [
            "unified modeling language",
            "UML profiles",
            "software engineering",
            "domain-specific modeling languages",
            "domain-specific languages",
            "modeling techniques",
            "UML",
            "extensibility mechanisms",
            "UML 2.1",
            "software design",
            "model-driven development",
            "software modeling",
            "UML extensions",
            "profile definition",
            "software quality",
            "technical correctness"
        ],
        "gold_standard_ordered1": [
            "unified modeling language",
            "uml profiles",
            "software engineering",
            "domain specific modeling",
            "modeling languages",
            "model to model transformation",
            "object oriented programming",
            "model-driven engineering",
            "component-based software architecture",
            "uml diagrams",
            "software architecture",
            "computer programming languages",
            "computer systems programming"
        ],
        "skgc_precision": 0.5,
        "skgc_recall": 0.6153846153846154,
        "skgc_f1": 0.5517241379310345,
        "csoc_topics_ordered": [
            "unified modeling language",
            "uml profiles",
            "modeling languages",
            "domain specific modeling",
            "model-driven engineering",
            "software engineering",
            "uml diagrams",
            "computer programming languages",
            "object oriented programming",
            "computer systems programming",
            "semantics",
            "language design",
            "languages",
            "linguistics",
            "computational linguistics",
            "graphic methods",
            "program compilers",
            "query languages",
            "real time systems"
        ],
        "gold_standard_ordered2": [
            "unified modeling language",
            "uml profiles",
            "modeling languages",
            "domain specific modeling",
            "model-driven engineering",
            "software engineering",
            "uml diagrams",
            "computer programming languages",
            "object oriented programming",
            "computer systems programming",
            "model to model transformation",
            "component-based software architecture",
            "software architecture"
        ],
        "csoc_precision": 0.5789473684210527,
        "csoc_recall": 0.8461538461538461,
        "csoc_f1": 0.6875
    },
    {
        "title": "Exploring Content Models for Multi-Document Summarization",
        "keywords": [],
        "abstract": "We present an exploration of generative probabilistic models for multi-document summarization. Beginning with a simple word frequency based model (Nenkova and Vanderwende, 2005), we construct a sequence of models each injecting more structure into the representation of document set content and exhibiting ROUGE gains along the way. Our final model, HierSum, utilizes a hierarchical LDA-style model (Blei et al., 2004) to represent content specificity as a hierarchy of topic vocabulary distributions. At the task of producing generic DUC-style summaries, HierSum yields state-of-the-art ROUGE performance and in pairwise user evaluation strongly outperforms Toutanova et al. (2007)'s state-of-the-art discriminative system. We also explore HierSum's capacity to produce multiple 'topical summaries' in order to facilitate content discovery and navigation.",
        "csoc_result": [
            "probabilistic models",
            "text document",
            "correlation analysis",
            "vocabulary",
            "multimedia contents",
            "text mining",
            "multimedia services",
            "mathematics",
            "bayesian networks",
            "information retrieval systems",
            "linguistics",
            "probability distributions"
        ],
        "gold_standard": [
            "computational linguistics",
            "information retrieval",
            "probabilistic models",
            "natural language processing systems"
        ],
        "skgc_topics": [
            "multi-document summarization",
            "generative probabilistic models",
            "word frequency",
            "document set content",
            "ROUGE",
            "hierarchical LDA-style model",
            "topic vocabulary distributions",
            "generic DUC-style summaries",
            "topical summaries",
            "content models",
            "hierarchical models",
            "latent Dirichlet allocation",
            "probabilistic topic models",
            "text summarization",
            "natural language processing",
            "information retrieval",
            "document clustering",
            "content discovery",
            "content navigation"
        ],
        "skgc_topics_ordered": [
            "information retrieval",
            "probabilistic topic models",
            "natural language processing",
            "generative probabilistic models",
            "hierarchical LDA-style model",
            "latent Dirichlet allocation",
            "multi-document summarization",
            "word frequency",
            "document set content",
            "ROUGE",
            "topic vocabulary distributions",
            "generic DUC-style summaries",
            "topical summaries",
            "content models",
            "hierarchical models",
            "text summarization",
            "document clustering",
            "content discovery",
            "content navigation"
        ],
        "gold_standard_ordered1": [
            "information retrieval",
            "probabilistic models",
            "natural language processing systems",
            "computational linguistics"
        ],
        "skgc_precision": 0.15789473684210525,
        "skgc_recall": 0.75,
        "skgc_f1": 0.2608695652173913,
        "csoc_topics_ordered": [
            "probabilistic models",
            "information retrieval systems",
            "linguistics",
            "probability distributions",
            "text document",
            "correlation analysis",
            "vocabulary",
            "multimedia contents",
            "text mining",
            "multimedia services",
            "mathematics",
            "bayesian networks"
        ],
        "gold_standard_ordered2": [
            "probabilistic models",
            "information retrieval",
            "computational linguistics",
            "natural language processing systems"
        ],
        "csoc_precision": 0.25,
        "csoc_recall": 0.75,
        "csoc_f1": 0.375
    },
    {
        "title": "ArnetMiner: extraction and mining of academic social networks",
        "keywords": [
            "Social Network",
            "Information Extraction",
            "Name Disambiguation",
            "Topic Modeling",
            "Expertise Search",
            "Association Search"
        ],
        "abstract": "This paper addresses several key issues in the ArnetMiner system, which aims at extracting and mining academic social networks. Specifically, the system focuses on: 1) Extracting researcher profiles automatically from the Web; 2) Integrating the publication data into the network from existing digital libraries; 3) Modeling the entire academic network; and 4) Providing search services for the academic network. So far, 448,470 researcher profiles have been extracted using a unified tagging approach. We integrate publications from online Web databases and propose a probabilistic framework to deal with the name ambiguity problem. Furthermore, we propose a unified modeling approach to simultaneously model topical aspects of papers, authors, and publication venues. Search services such as expertise search and people association search have been provided based on the modeling results. In this paper, we describe the architecture and main features of the system. We also present the empirical evaluation of the proposed methods.",
        "csoc_result": [
            "search process",
            "information extraction",
            "probabilistic framework",
            "digital libraries",
            "database",
            "social networks",
            "network architecture",
            "search engines",
            "information retrieval",
            "computer vision",
            "user interfaces",
            "data mining",
            "information analysis",
            "evolutionary algorithms",
            "network protocols",
            "database systems",
            "natural language processing systems",
            "bayesian networks",
            "world wide web"
        ],
        "gold_standard": [
            "information extraction",
            "probabilistic framework",
            "data mining",
            "world wide web",
            "digital libraries",
            "social networks"
        ],
        "skgc_topics": [
            "social network",
            "information extraction",
            "name disambiguation",
            "topic modeling",
            "expertise search",
            "association search",
            "researcher profiles",
            "academic network",
            "publication data",
            "name ambiguity",
            "probabilistic framework",
            "unified modeling",
            "search services",
            "academic social networks",
            "digital libraries",
            "researcher profiling",
            "academic data mining",
            "academic search engines",
            "academic information retrieval",
            "academic collaboration",
            "academic expertise",
            "academic association",
            "academic publications",
            "academic data integration"
        ],
        "skgc_topics_ordered": [
            "information extraction",
            "probabilistic framework",
            "digital libraries",
            "social network",
            "topic modeling",
            "expertise search",
            "association search",
            "researcher profiles",
            "academic network",
            "publication data",
            "name ambiguity",
            "unified modeling",
            "search services",
            "academic social networks",
            "researcher profiling",
            "academic data mining",
            "academic search engines",
            "academic information retrieval",
            "academic collaboration",
            "academic expertise",
            "academic association",
            "academic publications",
            "academic data integration"
        ],
        "gold_standard_ordered1": [
            "information extraction",
            "probabilistic framework",
            "digital libraries",
            "social networks",
            "data mining",
            "world wide web"
        ],
        "skgc_precision": 0.17391304347826086,
        "skgc_recall": 0.6666666666666666,
        "skgc_f1": 0.27586206896551724,
        "csoc_topics_ordered": [
            "information extraction",
            "probabilistic framework",
            "digital libraries",
            "social networks",
            "data mining",
            "world wide web",
            "search process",
            "database",
            "network architecture",
            "search engines",
            "information retrieval",
            "computer vision",
            "user interfaces",
            "information analysis",
            "evolutionary algorithms",
            "network protocols",
            "database systems",
            "natural language processing systems",
            "bayesian networks"
        ],
        "gold_standard_ordered2": [
            "information extraction",
            "probabilistic framework",
            "digital libraries",
            "social networks",
            "data mining",
            "world wide web"
        ],
        "csoc_precision": 0.3157894736842105,
        "csoc_recall": 1.0,
        "csoc_f1": 0.4799999999999999
    },
    {
        "title": "Classification using intersection kernel support vector machines is efficient",
        "keywords": [
            "approximation theory",
            "pattern classification",
            "support vector machines"
        ],
        "abstract": "Straightforward classification using kernelized SVMs requires evaluating the kernel for a test vector and each of the support vectors. For a class of kernels we show that one can do this much more efficiently. In particular we show that one can build histogram intersection kernel SVMs (IKSVMs) with runtime complexity of the classifier logarithmic in the number of support vectors as opposed to linear for the standard approach. We further show that by precomputing auxiliary tables we can construct an approximate classifier with constant runtime and space requirements, independent of the number of support vectors, with negligible loss in classification accuracy on various tasks. This approximation also applies to 1 - chi 2  and other kernels of similar form. We also introduce novel features based on a multi-level histograms of oriented edge energy and present experiments on various detection datasets. On the INRIA pedestrian dataset an approximate IKSVM classifier based on these features has the current best performance, with a miss rate 13% lower at 10 -6  False Positive Per Window than the linear SVM detector of Dalal & Triggs. On the Daimler Chrysler pedestrian dataset IKSVM gives comparable accuracy to the best results (based on quadratic SVM), while being 15times faster. In these experiments our approximate IKSVM is up to 2000times faster than a standard implementation and requires 200times less memory. Finally we show that a 50times speedup is possible using approximate IKSVM based on spatial pyramid features on the Caltech 101 dataset with negligible loss of accuracy.",
        "csoc_result": [
            "support vector machine",
            "pattern classification",
            "svm",
            "k-nearest neighbor classifier",
            "approximation theory",
            "test vectors",
            "bayes classifier",
            "support vector",
            "classifiers",
            "pattern recognition",
            "classification methods",
            "mathematics",
            "k-nearest neighbors",
            "neural networks",
            "test generations",
            "machine learning"
        ],
        "gold_standard": [
            "classifiers",
            "support vector machine",
            "approximation theory",
            "pattern classification",
            "machine learning",
            "pattern recognition",
            "classification methods",
            "test vectors",
            "support vector",
            "svm"
        ],
        "skgc_topics": [
            "approximation theory",
            "pattern classification",
            "support vector machines",
            "kernelized SVMs",
            "histogram intersection kernel",
            "runtime complexity",
            "classifier",
            "auxiliary tables",
            "approximate classifier",
            "multi-level histograms",
            "oriented edge energy",
            "detection datasets",
            "INRIA pedestrian dataset",
            "Daimler Chrysler pedestrian dataset",
            "spatial pyramid features",
            "Caltech 101 dataset",
            "machine learning",
            "kernel methods",
            "pedestrian detection",
            "object detection",
            "computer vision",
            "chi-squared kernel",
            "feature extraction",
            "histogram of oriented gradients",
            "SVM optimization",
            "large-scale classification",
            "computational efficiency",
            "image classification",
            "support vector classification",
            "quadratic SVM",
            "linear SVM",
            "spatial pyramid matching"
        ],
        "skgc_topics_ordered": [
            "approximation theory",
            "pattern classification",
            "machine learning",
            "classifier",
            "support vector machines",
            "kernelized SVMs",
            "histogram intersection kernel",
            "runtime complexity",
            "auxiliary tables",
            "approximate classifier",
            "multi-level histograms",
            "oriented edge energy",
            "detection datasets",
            "INRIA pedestrian dataset",
            "Daimler Chrysler pedestrian dataset",
            "spatial pyramid features",
            "Caltech 101 dataset",
            "kernel methods",
            "pedestrian detection",
            "object detection",
            "computer vision",
            "chi-squared kernel",
            "feature extraction",
            "histogram of oriented gradients",
            "SVM optimization",
            "large-scale classification",
            "computational efficiency",
            "image classification",
            "support vector classification",
            "quadratic SVM",
            "linear SVM",
            "spatial pyramid matching"
        ],
        "gold_standard_ordered1": [
            "approximation theory",
            "pattern classification",
            "machine learning",
            "classifiers",
            "support vector machine",
            "pattern recognition",
            "classification methods",
            "test vectors",
            "support vector",
            "svm"
        ],
        "skgc_precision": 0.1875,
        "skgc_recall": 0.6,
        "skgc_f1": 0.2857142857142857,
        "csoc_topics_ordered": [
            "support vector machine",
            "pattern classification",
            "svm",
            "approximation theory",
            "test vectors",
            "classifiers",
            "pattern recognition",
            "classification methods",
            "machine learning",
            "support vector",
            "k-nearest neighbor classifier",
            "bayes classifier",
            "mathematics",
            "k-nearest neighbors",
            "neural networks",
            "test generations"
        ],
        "gold_standard_ordered2": [
            "support vector machine",
            "pattern classification",
            "svm",
            "approximation theory",
            "test vectors",
            "classifiers",
            "pattern recognition",
            "classification methods",
            "machine learning",
            "support vector"
        ],
        "csoc_precision": 0.625,
        "csoc_recall": 1.0,
        "csoc_f1": 0.7692307692307693
    },
    {
        "title": "Distant supervision for relation extraction without labeled data",
        "keywords": [],
        "abstract": "Modern models of relation extraction for tasks like ACE are based on supervised learning of relations from small hand-labeled corpora. We investigate an alternative paradigm that does not require labeled corpora, avoiding the domain dependence of ACE-style algorithms, and allowing the use of corpora of any size. Our experiments use Freebase, a large semantic database of several thousand relations, to provide distant supervision. For each pair of entities that appears in some Freebase relation, we find all sentences containing those entities in a large unlabeled corpus and extract textual features to train a relation classifier. Our algorithm combines the advantages of supervised IE (combining 400,000 noisy pattern features in a probabilistic classifier) and unsupervised IE (extracting large numbers of relations from large corpora of any domain). Our model is able to extract 10,000 instances of 102 relations at a precision of 67.6%. We also analyze feature performance, showing that syntactic parse features are particularly helpful for relations that are ambiguous or lexically distant in their expression.",
        "csoc_result": [
            "syntactic structure",
            "syntactics",
            "relation extraction",
            "learning",
            "named entity recognition",
            "bayesian classifier",
            "unsupervised learning",
            "k-nearest neighbor classifier",
            "dbpedia",
            "bayes classifier",
            "database",
            "pattern",
            "word sense disambiguation",
            "classifiers",
            "semantics",
            "classification methods",
            "wordnet",
            "information retrieval",
            "natural language processing",
            "natural language processing systems",
            "software architecture",
            "bayesian networks",
            "education",
            "clustering algorithms",
            "information extraction",
            "computational linguistics",
            "machine learning",
            "database systems",
            "k-nearest neighbors",
            "linked data"
        ],
        "gold_standard": [
            "natural language processing",
            "information extraction",
            "syntactics",
            "unsupervised learning",
            "machine learning",
            "relation extraction",
            "syntactic structure",
            "classification methods"
        ],
        "skgc_topics": [
            "relation extraction",
            "distant supervision",
            "labeled data",
            "supervised learning",
            "hand-labeled corpora",
            "domain dependence",
            "Freebase",
            "semantic database",
            "entities",
            "textual features",
            "relation classifier",
            "supervised IE",
            "unsupervised IE",
            "syntactic parse features",
            "information extraction",
            "natural language processing",
            "machine learning",
            "probabilistic classifier",
            "large corpora",
            "feature analysis",
            "syntactic features",
            "relation learning",
            "semantic relations",
            "knowledge base",
            "data mining",
            "text mining"
        ],
        "skgc_topics_ordered": [
            "relation extraction",
            "natural language processing",
            "information extraction",
            "machine learning",
            "unsupervised IE",
            "supervised IE",
            "syntactic parse features",
            "syntactic features",
            "supervised learning",
            "probabilistic classifier",
            "large corpora",
            "feature analysis",
            "relation learning",
            "semantic relations",
            "knowledge base",
            "data mining",
            "text mining",
            "distant supervision",
            "labeled data",
            "hand-labeled corpora",
            "domain dependence",
            "Freebase",
            "semantic database",
            "entities",
            "textual features",
            "relation classifier"
        ],
        "gold_standard_ordered1": [
            "relation extraction",
            "natural language processing",
            "information extraction",
            "machine learning",
            "unsupervised learning",
            "syntactics",
            "syntactic structure",
            "classification methods"
        ],
        "skgc_precision": 0.3076923076923077,
        "skgc_recall": 1.0,
        "skgc_f1": 0.47058823529411764,
        "csoc_topics_ordered": [
            "natural language processing",
            "information extraction",
            "syntactics",
            "unsupervised learning",
            "machine learning",
            "relation extraction",
            "syntactic structure",
            "classification methods",
            "learning",
            "named entity recognition",
            "bayesian classifier",
            "k-nearest neighbor classifier",
            "dbpedia",
            "bayes classifier",
            "database",
            "pattern",
            "word sense disambiguation",
            "classifiers",
            "semantics",
            "natural language processing systems",
            "software architecture",
            "bayesian networks",
            "education",
            "clustering algorithms",
            "computational linguistics",
            "database systems",
            "k-nearest neighbors",
            "linked data",
            "information retrieval"
        ],
        "gold_standard_ordered2": [
            "natural language processing",
            "information extraction",
            "syntactics",
            "unsupervised learning",
            "machine learning",
            "relation extraction",
            "syntactic structure",
            "classification methods"
        ],
        "csoc_precision": 0.27586206896551724,
        "csoc_recall": 1.0,
        "csoc_f1": 0.4324324324324324
    },
    {
        "title": "Matrix \"Bit\" loaded: a scalable lightweight join query processor for RDF data",
        "keywords": [],
        "abstract": "The Semantic Web community, until now, has used traditional database systems for the storage and querying of RDF data. The SPARQL query language also closely follows SQL syntax. As a natural consequence, most of the SPARQL query processing techniques are based on database query processing and optimization techniques. For SPARQL join query optimization, previous works like RDF-3X and Hexastore have proposed to use 6-way indexes on the RDF data. Although these indexes speed up merge-joins by orders of magnitude, for complex join queries generating large intermediate join results, the scalability of the query processor still remains a challenge.   In this paper, we introduce (i) BitMat - a compressed bit-matrix structure for storing huge RDF graphs, and (ii) a novel, light-weight SPARQL join query processing method that employs an initial pruning technique, followed by a variable-binding-matching algorithm on BitMats to produce the final results. Our query processing method does not build intermediate join tables and works directly on the compressed data. We have demonstrated our method against RDF graphs of upto 1.33 billion triples - the largest among results published until now (single-node, non-parallel systems), and have compared our method with the state-of-the-art RDF stores - RDF-3X and MonetDB. Our results show that the competing methods are most effective with highly selective queries. On the other hand, BitMat can deliver 2-3 orders of magnitude better performance on complex, low-selectivity queries over massive data.",
        "csoc_result": [
            "rdf data",
            "query optimization",
            "sql",
            "sql query",
            "query processing",
            "sparql",
            "semantic web",
            "rdf graph",
            "query languages",
            "database",
            "database systems",
            "rdf",
            "optimization problems",
            "query evaluation",
            "computer systems",
            "search engines",
            "relational database",
            "correlation analysis",
            "resource description framework",
            "semantics",
            "world wide web"
        ],
        "gold_standard": [
            "relational database",
            "query processing",
            "sparql",
            "query optimization",
            "world wide web",
            "rdf graph",
            "database systems",
            "query evaluation",
            "optimization",
            "resource description framework",
            "rdf data",
            "database",
            "query languages",
            "semantic web",
            "rdf"
        ],
        "skgc_topics": [
            "SPARQL",
            "RDF data",
            "query processing",
            "optimization techniques",
            "BitMat",
            "compressed bit-matrix",
            "RDF graphs",
            "variable-binding-matching algorithm",
            "intermediate join results",
            "scalability",
            "RDF-3X",
            "Hexastore",
            "MonetDB",
            "semantic web",
            "RDF storage",
            "query optimization",
            "graph databases",
            "data compression",
            "large-scale data processing",
            "RDF indexing",
            "join query processing",
            "database systems",
            "SPARQL optimization",
            "RDF query processing",
            "data scalability",
            "RDF triples",
            "RDF stores"
        ],
        "skgc_topics_ordered": [
            "SPARQL",
            "RDF data",
            "query processing",
            "optimization techniques",
            "semantic web",
            "RDF graphs",
            "database systems",
            "query optimization",
            "RDF storage",
            "RDF indexing",
            "RDF query processing",
            "RDF triples",
            "RDF stores",
            "BitMat",
            "compressed bit-matrix",
            "variable-binding-matching algorithm",
            "intermediate join results",
            "scalability",
            "RDF-3X",
            "Hexastore",
            "MonetDB",
            "graph databases",
            "data compression",
            "large-scale data processing",
            "join query processing",
            "SPARQL optimization",
            "data scalability"
        ],
        "gold_standard_ordered1": [
            "SPARQL",
            "RDF data",
            "query processing",
            "query optimization",
            "semantic web",
            "RDF graph",
            "database systems",
            "optimization",
            "RDF",
            "query evaluation",
            "resource description framework",
            "database",
            "query languages",
            "world wide web",
            "relational database"
        ],
        "skgc_precision": 0.48148148148148145,
        "skgc_recall": 0.8666666666666667,
        "skgc_f1": 0.6190476190476191,
        "csoc_topics_ordered": [
            "rdf data",
            "query optimization",
            "query processing",
            "sparql",
            "semantic web",
            "rdf graph",
            "database systems",
            "query evaluation",
            "resource description framework",
            "relational database",
            "database",
            "query languages",
            "world wide web",
            "rdf",
            "optimization problems",
            "sql",
            "sql query",
            "computer systems",
            "search engines",
            "correlation analysis",
            "semantics"
        ],
        "gold_standard_ordered2": [
            "rdf data",
            "query optimization",
            "query processing",
            "sparql",
            "semantic web",
            "rdf graph",
            "database systems",
            "query evaluation",
            "resource description framework",
            "relational database",
            "database",
            "query languages",
            "world wide web",
            "rdf",
            "optimization"
        ],
        "csoc_precision": 0.6666666666666666,
        "csoc_recall": 0.9333333333333333,
        "csoc_f1": 0.7777777777777778
    },
    {
        "title": "Exhibit: lightweight structured data publishing",
        "keywords": [
            "Publish",
            "presentation",
            "faceted browsing",
            "lens",
            "view",
            "template"
        ],
        "abstract": "The early Web was hailed for giving individuals the same publishing power as large content providers. But over time, large content providers learned to exploit the structure in their data, leveraging databases and server side technologies to provide rich browsing and visualization. Individual authors fall behind once more: neither old-fashioned static pages nor domain-specific publishing frameworks supporting limited customization can match custom database-backed web applications.   In this paper, we propose Exhibit, a lightweight framework for publishing structured data on standard web servers that requires no installation, database administration, or programming. Exhibit lets authors with relatively limited skills-those same enthusiasts who could write HTML pages for the early Web-publish richly interactive pages that exploit the structure of their data for better browsing and visualization. Such structured publishing in turn makes that data more useful to all of its consumers: individual readers get more powerful interfaces, mashup creators can more easily repurpose the data, and Semantic Web enthusiasts can feed the data to the nascent Semantic Web.",
        "csoc_result": [
            "ajax",
            "visualization",
            "content providers",
            "mashup",
            "html",
            "world wide web",
            "semantic web",
            "database",
            "web application",
            "web servers",
            "html pages",
            "data publishing",
            "xml",
            "javascript",
            "servers",
            "internet",
            "user interfaces",
            "content based retrieval",
            "web 2.0",
            "human computer interaction",
            "internet service providers",
            "database systems",
            "semantics",
            "k-anonymity"
        ],
        "gold_standard": [
            "web 2.0",
            "user interfaces",
            "data publishing",
            "visualization tools",
            "web page",
            "servers",
            "html pages",
            "information management",
            "semantics",
            "web development",
            "xml",
            "web application",
            "semantic desktop",
            "information content",
            "mashup",
            "visualization",
            "javascript",
            "semantic web",
            "personal information",
            "human computer interaction",
            "web servers",
            "content providers",
            "database systems",
            "data visualization",
            "internet",
            "rdf data",
            "database",
            "world wide web",
            "information visualization",
            "graphical user interfaces",
            "ajax",
            "html",
            "rdf"
        ],
        "skgc_topics": [
            "structured data",
            "publishing",
            "faceted browsing",
            "visualization",
            "web servers",
            "interactive pages",
            "semantic web",
            "mashup creators",
            "data publishing",
            "data visualization",
            "web applications",
            "data structure",
            "web publishing",
            "interactive web pages",
            "data presentation",
            "web frameworks",
            "data interfaces",
            "data repurposing",
            "semantic web technologies"
        ],
        "skgc_topics_ordered": [
            "data publishing",
            "visualization",
            "web servers",
            "semantic web",
            "mashup creators",
            "data visualization",
            "web applications",
            "structured data",
            "publishing",
            "faceted browsing",
            "interactive pages",
            "data structure",
            "web publishing",
            "interactive web pages",
            "data presentation",
            "web frameworks",
            "data interfaces",
            "data repurposing",
            "semantic web technologies"
        ],
        "gold_standard_ordered1": [
            "data publishing",
            "visualization",
            "web servers",
            "semantic web",
            "mashup",
            "data visualization",
            "web application",
            "web 2.0",
            "user interfaces",
            "web page",
            "servers",
            "html pages",
            "information management",
            "semantics",
            "web development",
            "xml",
            "semantic desktop",
            "information content",
            "personal information",
            "human computer interaction",
            "content providers",
            "database systems",
            "internet",
            "rdf data",
            "database",
            "world wide web",
            "information visualization",
            "graphical user interfaces",
            "ajax",
            "html",
            "rdf"
        ],
        "skgc_precision": 0.3684210526315789,
        "skgc_recall": 0.22580645161290322,
        "skgc_f1": 0.28,
        "csoc_topics_ordered": [
            "web 2.0",
            "user interfaces",
            "data publishing",
            "visualization",
            "web application",
            "web servers",
            "html pages",
            "semantics",
            "xml",
            "mashup",
            "semantic web",
            "content providers",
            "database systems",
            "internet",
            "database",
            "world wide web",
            "ajax",
            "html",
            "javascript",
            "human computer interaction",
            "content based retrieval",
            "internet service providers",
            "k-anonymity"
        ],
        "gold_standard_ordered2": [
            "web 2.0",
            "user interfaces",
            "data publishing",
            "visualization",
            "web application",
            "web servers",
            "html pages",
            "semantics",
            "xml",
            "mashup",
            "semantic web",
            "content providers",
            "database systems",
            "internet",
            "database",
            "world wide web",
            "ajax",
            "html",
            "javascript",
            "human computer interaction",
            "information management",
            "web development",
            "semantic desktop",
            "information content",
            "personal information",
            "data visualization",
            "rdf data",
            "information visualization",
            "graphical user interfaces",
            "rdf"
        ],
        "csoc_precision": 0.9130434782608695,
        "csoc_recall": 0.7,
        "csoc_f1": 0.7924528301886793
    },
    {
        "title": "Linguistically Motivated Large-Scale NLP with C&C and Boxer",
        "keywords": [],
        "abstract": "The statistical modelling of language, together with advances in wide-coverage grammar development, have led to high levels of robustness and efficiency in NLP systems and made linguistically motivated large-scale language processing a possibility (Matsuzaki et al., 2007; Kaplan et al., 2004). This paper describes an NLP system which is based on syntactic and semantic formalisms from theoretical linguistics, and which we have used to analyse the entire Gigaword corpus (1 billion words) in less than 5 days using only 18 processors. This combination of detail and speed of analysis represents a break-through in NLP technology.",
        "csoc_result": [
            "syntactics",
            "linguistics",
            "computational linguistics",
            "modeling languages",
            "natural language processing",
            "semantics",
            "languages",
            "computer programming languages",
            "query languages",
            "database systems",
            "object oriented programming",
            "natural language processing systems",
            "software engineering"
        ],
        "gold_standard": [
            "semantics",
            "natural language processing",
            "computational linguistics",
            "modeling languages",
            "linguistics",
            "natural language processing systems"
        ],
        "skgc_topics": [
            "syntactic formalisms",
            "semantic formalisms",
            "theoretical linguistics",
            "NLP systems",
            "large-scale language processing",
            "statistical modelling of language",
            "wide-coverage grammar development",
            "Gigaword corpus",
            "natural language processing",
            "computational linguistics",
            "language technology",
            "corpus linguistics",
            "linguistic analysis",
            "semantic parsing",
            "syntactic parsing",
            "grammar-based NLP",
            "high-performance NLP",
            "large-scale text analysis",
            "linguistic data processing"
        ],
        "skgc_topics_ordered": [
            "natural language processing",
            "computational linguistics",
            "syntactic formalisms",
            "semantic formalisms",
            "theoretical linguistics",
            "NLP systems",
            "large-scale language processing",
            "statistical modelling of language",
            "wide-coverage grammar development",
            "Gigaword corpus",
            "language technology",
            "corpus linguistics",
            "linguistic analysis",
            "semantic parsing",
            "syntactic parsing",
            "grammar-based NLP",
            "high-performance NLP",
            "large-scale text analysis",
            "linguistic data processing"
        ],
        "gold_standard_ordered1": [
            "natural language processing",
            "computational linguistics",
            "semantics",
            "modeling languages",
            "linguistics",
            "natural language processing systems\n\"\"\""
        ],
        "skgc_precision": 0.21052631578947367,
        "skgc_recall": 0.6666666666666666,
        "skgc_f1": 0.32,
        "csoc_topics_ordered": [
            "semantics",
            "natural language processing",
            "computational linguistics",
            "modeling languages",
            "linguistics",
            "natural language processing systems",
            "syntactics",
            "languages",
            "computer programming languages",
            "query languages",
            "database systems",
            "object oriented programming",
            "software engineering"
        ],
        "gold_standard_ordered2": [
            "semantics",
            "natural language processing",
            "computational linguistics",
            "modeling languages",
            "linguistics",
            "natural language processing systems\n\"\"\""
        ],
        "csoc_precision": 0.46153846153846156,
        "csoc_recall": 1.0,
        "csoc_f1": 0.631578947368421
    },
    {
        "title": "Learning deep structured semantic models for web search using clickthrough data",
        "keywords": [
            "semantic model",
            "deep learning",
            "web search",
            "clickthrough data"
        ],
        "abstract": "Latent semantic models, such as LSA, intend to map a query to its relevant documents at the semantic level where keyword-based matching often fails. In this study we strive to develop a series of new latent semantic models with a deep structure that project queries and documents into a common low-dimensional space where the relevance of a document given a query is readily computed as the distance between them. The proposed deep structured semantic models are discriminatively trained by maximizing the conditional likelihood of the clicked documents given a query using the clickthrough data. To make our models applicable to large-scale Web search applications, we also use a technique called word hashing, which is shown to effectively scale up our semantic models to handle large vocabularies which are common in such tasks. The new models are evaluated on a Web document ranking task using a real-world data set. Results show that our best model significantly outperforms other latent semantic models, which were considered state-of-the-art in the performance prior to the work presented in this paper.",
        "csoc_result": [
            "semantic levels",
            "hashing",
            "semantics",
            "low-dimensional spaces",
            "learning",
            "search engines",
            "web searches",
            "deep learning",
            "query log analysis",
            "clickthrough data",
            "image retrieval",
            "manifold learning",
            "ontology",
            "online searching",
            "world wide web",
            "neural networks",
            "education",
            "database systems",
            "information theory",
            "query logs",
            "hash functions"
        ],
        "gold_standard": [
            "computational linguistics",
            "online searching",
            "information retrieval",
            "web page",
            "query log analysis",
            "distribution functions",
            "semantics",
            "context-aware recommender systems",
            "learning",
            "web searches",
            "probability distribution function",
            "neural networks",
            "low-dimensional spaces",
            "hash functions",
            "clickthrough data",
            "query logs",
            "semantic levels",
            "deep learning",
            "natural language processing systems",
            "question answering",
            "hashing",
            "recommender systems",
            "world wide web",
            "information theory"
        ],
        "skgc_topics": [
            "deep learning",
            "web search",
            "clickthrough data",
            "latent semantic models",
            "word hashing",
            "document ranking",
            "conditional likelihood",
            "low-dimensional space",
            "information retrieval",
            "search engine optimization",
            "query-document matching",
            "semantic search",
            "deep structured models",
            "large-scale web search",
            "machine learning",
            "natural language processing",
            "neural networks",
            "relevance ranking",
            "user behavior analysis"
        ],
        "skgc_topics_ordered": [
            "deep learning",
            "web search",
            "clickthrough data",
            "information retrieval",
            "neural networks",
            "low-dimensional space",
            "word hashing",
            "machine learning",
            "natural language processing",
            "semantic search",
            "query-document matching",
            "document ranking",
            "conditional likelihood",
            "deep structured models",
            "large-scale web search",
            "relevance ranking",
            "user behavior analysis",
            "search engine optimization"
        ],
        "gold_standard_ordered1": [
            "deep learning",
            "web searches",
            "clickthrough data",
            "information retrieval",
            "neural networks",
            "low-dimensional spaces",
            "hash functions",
            "learning",
            "natural language processing systems",
            "semantics",
            "query log analysis",
            "distribution functions",
            "probability distribution function",
            "context-aware recommender systems",
            "question answering",
            "online searching",
            "query logs",
            "information theory",
            "web page",
            "world wide web",
            "hashing",
            "recommender systems"
        ],
        "skgc_precision": 0.5555555555555556,
        "skgc_recall": 0.45454545454545453,
        "skgc_f1": 0.5,
        "csoc_topics_ordered": [
            "semantic levels",
            "hashing",
            "semantics",
            "low-dimensional spaces",
            "learning",
            "web searches",
            "deep learning",
            "query log analysis",
            "clickthrough data",
            "neural networks",
            "query logs",
            "hash functions",
            "online searching",
            "world wide web",
            "information theory",
            "search engines",
            "ontology",
            "manifold learning",
            "image retrieval",
            "education",
            "database systems"
        ],
        "gold_standard_ordered2": [
            "semantic levels",
            "hashing",
            "semantics",
            "low-dimensional spaces",
            "learning",
            "web searches",
            "deep learning",
            "query log analysis",
            "clickthrough data",
            "neural networks",
            "query logs",
            "hash functions",
            "online searching",
            "world wide web",
            "information theory",
            "computational linguistics",
            "probability distribution function",
            "distribution functions",
            "web page",
            "context-aware recommender systems",
            "natural language processing systems",
            "question answering",
            "recommender systems"
        ],
        "csoc_precision": 0.7619047619047619,
        "csoc_recall": 0.6956521739130435,
        "csoc_f1": 0.7272727272727272
    },
    {
        "title": "Linked open data to support content-based recommender systems",
        "keywords": [
            "Content-based Recommender Systems",
            "Vector Space Model",
            "Linked Data",
            "DBpedia",
            "LinkedMDB",
            "Freebase",
            "Semantic Web",
            "MovieLens",
            "Precision",
            "Recall"
        ],
        "abstract": "The World Wide Web is moving from a Web of hyper-linked Documents to a Web of linked Data. Thanks to the Semantic Web spread and to the more recent Linked Open Data (LOD) initiative, a vast amount of RDF data have been published in freely accessible datasets. These datasets are connected with each other to form the so called Linked Open Data cloud. As of today, there are tons of RDF data available in the Web of Data, but only few applications really exploit their potential power. In this paper we show how these data can successfully be used to develop a recommender system (RS) that relies exclusively on the information encoded in the Web of Data. We implemented a content-based RS that leverages the data available within Linked Open Data datasets (in particular DBpedia, Freebase and LinkedMDB) in order to recommend movies to the end users. We extensively evaluated the approach and validated the effectiveness of the algorithms by experimentally measuring their accuracy with precision and recall metrics.",
        "csoc_result": [
            "content-based",
            "rdf data",
            "collaborative filtering techniques",
            "world wide web",
            "recommendation systems",
            "collaborative filtering",
            "semantic web",
            "vector space models",
            "dbpedia",
            "linked open data",
            "recommender systems",
            "rdf",
            "linked data",
            "data handling",
            "internet",
            "query processing",
            "information retrieval",
            "content based retrieval",
            "resource description framework",
            "semantics"
        ],
        "gold_standard": [
            "recommender systems",
            "semantic web",
            "world wide web",
            "semantics",
            "dbpedia",
            "recommendation systems",
            "information retrieval",
            "linked open data",
            "vector space models",
            "semantic search",
            "internet",
            "content-based",
            "rdf data",
            "linked data",
            "rdf"
        ],
        "skgc_topics": [
            "linked open data",
            "content-based recommender systems",
            "vector space model",
            "linked data",
            "DBpedia",
            "LinkedMDB",
            "Freebase",
            "semantic web",
            "MovieLens",
            "precision",
            "recall",
            "RDF data",
            "Web of Data",
            "recommender system",
            "datasets",
            "information retrieval",
            "recommendation systems",
            "linked open data cloud",
            "semantic data",
            "movie recommendation",
            "data integration",
            "knowledge graphs",
            "RDF triples",
            "data interlinking",
            "personalized recommendations",
            "semantic search",
            "data mining",
            "ontology",
            "knowledge representation"
        ],
        "skgc_topics_ordered": [
            "linked open data",
            "content-based recommender systems",
            "vector space model",
            "linked data",
            "DBpedia",
            "semantic web",
            "precision",
            "recall",
            "RDF data",
            "recommender system",
            "information retrieval",
            "recommendation systems",
            "Freebase",
            "MovieLens",
            "Web of Data",
            "datasets",
            "linked open data cloud",
            "semantic data",
            "movie recommendation",
            "data integration",
            "knowledge graphs",
            "RDF triples",
            "data interlinking",
            "personalized recommendations",
            "semantic search",
            "data mining",
            "ontology",
            "knowledge representation",
            "LinkedMDB"
        ],
        "gold_standard_ordered1": [
            "linked open data",
            "recommender systems",
            "vector space models",
            "linked data",
            "dbpedia",
            "semantic web",
            "rdf data",
            "recommendation systems",
            "information retrieval",
            "semantic search",
            "world wide web",
            "semantics",
            "internet",
            "content-based",
            "rdf"
        ],
        "skgc_precision": 0.4827586206896552,
        "skgc_recall": 0.9333333333333333,
        "skgc_f1": 0.6363636363636364,
        "csoc_topics_ordered": [
            "recommender systems",
            "semantic web",
            "world wide web",
            "semantics",
            "dbpedia",
            "recommendation systems",
            "information retrieval",
            "linked open data",
            "vector space models",
            "rdf data",
            "linked data",
            "rdf",
            "content-based",
            "collaborative filtering techniques",
            "internet",
            "content based retrieval",
            "resource description framework",
            "data handling",
            "query processing",
            "collaborative filtering"
        ],
        "gold_standard_ordered2": [
            "recommender systems",
            "semantic web",
            "world wide web",
            "semantics",
            "dbpedia",
            "recommendation systems",
            "information retrieval",
            "linked open data",
            "vector space models",
            "rdf data",
            "linked data",
            "rdf",
            "content-based",
            "semantic search",
            "internet"
        ],
        "csoc_precision": 0.65,
        "csoc_recall": 0.8666666666666667,
        "csoc_f1": 0.7428571428571429
    },
    {
        "title": "Expertise networks in online communities: structure and algorithms",
        "keywords": [
            "Social network analysis",
            "expertise finding",
            "expert locators",
            "help seeking",
            "online communities",
            "simulation"
        ],
        "abstract": "Web-based communities have become important places for people to seek and share expertise. We find that networks in these communities typically differ in their topology from other online networks such as the World Wide Web. Systems targeted to augment web-based communities by automatically identifying users with expertise, for example, need to adapt to the underlying interaction dynamics. In this study, we analyze the Java Forum, a large online help-seeking community, using social network analysis methods. We test a set of network-based ranking algorithms, including PageRank and HITS, on this large size social network in order to identify users with high expertise. We then use simulations to identify a small number of simple simulation rules governing the question-answer dynamic in the network. These simple rules not only replicate the structural characteristics and algorithm performance on the empirically observed Java Forum, but also allow us to evaluate how other algorithms may perform in communities with different characteristics. We believe this approach will be fruitful for practical algorithm design and implementation for online expertise-sharing communities.",
        "csoc_result": [
            "social network analysis",
            "topology",
            "network structures",
            "java",
            "online communities",
            "network communities",
            "social networks",
            "network architecture",
            "online social networks",
            "world wide web",
            "network analysis",
            "computer programming languages",
            "internet",
            "neural networks",
            "object oriented programming",
            "network protocols",
            "electric network analysis",
            "high level languages",
            "community detection",
            "online systems"
        ],
        "gold_standard": [
            "network analysis",
            "network structures",
            "social network analysis",
            "online social networks",
            "social networks",
            "network communities",
            "communities of practice",
            "online communities",
            "community of practice"
        ],
        "skgc_topics": [
            "expertise networks",
            "online communities",
            "social network analysis",
            "expertise finding",
            "help seeking",
            "simulation",
            "network-based ranking algorithms",
            "PageRank",
            "HITS",
            "question-answer dynamic",
            "expert locators",
            "community dynamics",
            "expertise sharing",
            "web-based communities",
            "network topology",
            "interaction dynamics",
            "algorithm performance",
            "practical algorithm design",
            "expertise identification",
            "social network structure"
        ],
        "skgc_topics_ordered": [
            "social network analysis",
            "online communities",
            "expertise networks",
            "network-based ranking algorithms",
            "PageRank",
            "HITS",
            "question-answer dynamic",
            "expert locators",
            "community dynamics",
            "expertise sharing",
            "web-based communities",
            "network topology",
            "interaction dynamics",
            "algorithm performance",
            "practical algorithm design",
            "expertise identification",
            "social network structure",
            "help seeking",
            "simulation"
        ],
        "gold_standard_ordered1": [
            "social network analysis",
            "online communities",
            "network structures",
            "online social networks",
            "social networks",
            "network communities",
            "communities of practice",
            "community of practice",
            "network analysis"
        ],
        "skgc_precision": 0.2631578947368421,
        "skgc_recall": 0.5555555555555556,
        "skgc_f1": 0.35714285714285715,
        "csoc_topics_ordered": [
            "social network analysis",
            "network structures",
            "online communities",
            "network communities",
            "social networks",
            "online social networks",
            "network analysis",
            "topology",
            "java",
            "network architecture",
            "world wide web",
            "computer programming languages",
            "internet",
            "neural networks",
            "object oriented programming",
            "network protocols",
            "electric network analysis",
            "high level languages",
            "community detection",
            "online systems"
        ],
        "gold_standard_ordered2": [
            "social network analysis",
            "network structures",
            "online communities",
            "network communities",
            "social networks",
            "online social networks",
            "network analysis",
            "communities of practice",
            "community of practice"
        ],
        "csoc_precision": 0.35,
        "csoc_recall": 0.7777777777777778,
        "csoc_f1": 0.48275862068965514
    },
    {
        "title": "The Vera am Mittag German audio-visual emotional speech database",
        "keywords": [
            "audio databases",
            "audio recording",
            "audio-visual systems",
            "emotion recognition",
            "linguistics",
            "natural language processing",
            "speech recognition"
        ],
        "abstract": "The lack of publicly available annotated databases is one of the major barriers to research advances on emotional information processing. In this contribution we present a recently collected database of spontaneous emotional speech in German which is being made available to the research community. The database consists of 12 hours of audio-visual recordings of the German TV talk show ldquoVera am Mittagrdquo, segmented into broadcasts, dialogue acts and utterances. This corpus contains spontaneous and very emotional speech recorded from unscripted, authentic discussions between the guests of the talk show. In addition to the audio-visual data and the segmented utterances we provide emotion labels for a great part of the data. The emotion labels are given on a continuous valued scale for three emotion primitives: valence, activation and dominance, using a large number of human evaluators. Such data is of great interest to all research groups working on spontaneous speech analysis, emotion recognition in both speech and facial expression, natural language understanding, and robust speech recognition.",
        "csoc_result": [
            "facial expression",
            "human emotion",
            "basic emotions",
            "audio",
            "speech data",
            "natural language understanding",
            "natural languages",
            "emotion recognition",
            "database",
            "speech analysis",
            "speech signals",
            "emotion expression",
            "automatic speech recognition",
            "speech synthesis",
            "linguistics",
            "speech recognition",
            "broadcast",
            "natural language processing",
            "speech database",
            "human motions",
            "audio-visual",
            "speech recognition systems",
            "dialogue",
            "natural speech",
            "emotional speech",
            "emotional expressions",
            "motion estimation",
            "speech processing",
            "human computer interaction",
            "signal processing",
            "speech communication",
            "natural language processing systems",
            "argumentation",
            "broadcasting",
            "ad hoc networks",
            "audio acoustics",
            "computational linguistics",
            "knowledge representation",
            "man machine systems",
            "face recognition",
            "database systems",
            "robotics",
            "affective computing",
            "gesture recognition",
            "semantics"
        ],
        "gold_standard": [
            "basic emotions",
            "computational linguistics",
            "emotion expression",
            "natural language understanding",
            "audio acoustics",
            "speech processing",
            "emotional speech",
            "speech recognition",
            "speech data",
            "facial expression",
            "audio information",
            "speech recognition systems",
            "speech communication",
            "dialogue",
            "human emotion",
            "audio",
            "emotion recognition",
            "natural languages",
            "speech database",
            "database systems",
            "database",
            "emotional expressions",
            "speech signals",
            "natural language processing systems",
            "natural speech",
            "natural language processing",
            "audio-visual",
            "gesture recognition",
            "automatic speech recognition",
            "speech analysis",
            "linguistics"
        ],
        "skgc_topics": [
            "audio databases",
            "audio-visual recordings",
            "emotion recognition",
            "linguistics",
            "natural language processing",
            "speech recognition",
            "emotional speech",
            "German",
            "spontaneous speech",
            "emotion labels",
            "valence",
            "activation",
            "dominance",
            "emotional information processing",
            "speech analysis",
            "facial expression recognition",
            "natural language understanding",
            "robust speech recognition",
            "emotion primitives",
            "annotated databases",
            "spontaneous emotional speech",
            "audio-visual emotional speech",
            "German TV talk show",
            "dialogue acts",
            "utterances",
            "human evaluators"
        ],
        "skgc_topics_ordered": [
            "emotional speech",
            "speech recognition",
            "emotion recognition",
            "linguistics",
            "natural language understanding",
            "natural language processing",
            "speech analysis",
            "facial expression recognition",
            "robust speech recognition",
            "German",
            "spontaneous speech",
            "emotion labels",
            "valence",
            "activation",
            "dominance",
            "emotional information processing",
            "annotated databases",
            "spontaneous emotional speech",
            "audio-visual emotional speech",
            "German TV talk show",
            "dialogue acts",
            "utterances",
            "human evaluators",
            "audio databases",
            "audio-visual recordings"
        ],
        "gold_standard_ordered1": [
            "emotional speech",
            "speech recognition",
            "emotion recognition",
            "linguistics",
            "natural language understanding",
            "natural language processing",
            "speech analysis",
            "facial expression",
            "speech recognition systems",
            "German",
            "natural languages",
            "emotion expression",
            "basic emotions",
            "human emotion",
            "emotional expressions",
            "speech data",
            "speech signals",
            "speech communication",
            "natural speech",
            "audio acoustics",
            "audio information",
            "audio",
            "audio-visual",
            "gesture recognition",
            "automatic speech recognition",
            "database",
            "database systems",
            "speech database"
        ],
        "skgc_precision": 0.8,
        "skgc_recall": 0.7142857142857143,
        "skgc_f1": 0.7547169811320756,
        "csoc_topics_ordered": [
            "basic emotions",
            "natural language understanding",
            "emotion recognition",
            "speech analysis",
            "linguistics",
            "speech recognition",
            "speech data",
            "facial expression",
            "emotion expression",
            "automatic speech recognition",
            "natural languages",
            "speech database",
            "emotional speech",
            "emotional expressions",
            "audio",
            "audio-visual",
            "speech recognition systems",
            "dialogue",
            "human emotion",
            "natural language processing",
            "natural language processing systems",
            "natural speech",
            "gesture recognition",
            "database",
            "database systems",
            "audio acoustics",
            "computational linguistics",
            "speech processing",
            "speech signals",
            "speech communication",
            "human computer interaction",
            "semantics",
            "face recognition",
            "robotics",
            "affective computing",
            "signal processing",
            "knowledge representation",
            "man machine systems",
            "motion estimation",
            "argumentation",
            "broadcasting",
            "broadcast",
            "ad hoc networks",
            "speech synthesis",
            "human motions"
        ],
        "gold_standard_ordered2": [
            "basic emotions",
            "natural language understanding",
            "emotion recognition",
            "speech analysis",
            "linguistics",
            "speech recognition",
            "speech data",
            "facial expression",
            "emotion expression",
            "automatic speech recognition",
            "natural languages",
            "speech database",
            "emotional speech",
            "emotional expressions",
            "audio",
            "audio-visual",
            "speech recognition systems",
            "dialogue",
            "human emotion",
            "natural language processing",
            "natural language processing systems",
            "natural speech",
            "gesture recognition",
            "database",
            "database systems",
            "audio acoustics",
            "computational linguistics",
            "speech processing",
            "speech signals",
            "speech communication",
            "semantics",
            "audio information",
            "human computer interaction",
            "face recognition",
            "robotics",
            "affective computing",
            "signal processing",
            "knowledge representation",
            "man machine systems",
            "motion estimation",
            "argumentation",
            "broadcasting"
        ],
        "csoc_precision": 0.9333333333333333,
        "csoc_recall": 1.0,
        "csoc_f1": 0.9655172413793104
    },
    {
        "title": "Inferring networks of diffusion and influence",
        "keywords": [
            "Networks of diffusion",
            "Information cascades",
            "Blogs",
            "News media",
            "Meme-tracking",
            "Social networks"
        ],
        "abstract": "Information diffusion and virus propagation are fundamental processes talking place in networks. While it is often possible to directly observe when nodes become infected, observing individual transmissions (i.e., who infects whom or who influences whom) is typically very difficult. Furthermore, in many applications, the underlying network over which the diffusions and propagations spread is actually unobserved. We tackle these challenges by developing a method for tracing paths of diffusion and influence through networks and inferring the networks over which contagions propagate. Given the times when nodes adopt pieces of information or become infected, we identify the optimal network that best explains the observed infection times. Since the optimization problem is NP-hard to solve exactly, we develop an efficient approximation algorithm that scales to large datasets and in practice gives provably near-optimal performance. We demonstrate the effectiveness of our approach by tracing information cascades in a set of 170 million blogs and news articles over a one year period to infer how information flows through the online media space. We find that the diffusion network of news tends to have a core-periphery structure with a small set of core media sites that diffuse information to the rest of the Web. These sites tend to have stable circles of influence with more general news media sites acting as connectors between them.",
        "csoc_result": [
            "audio-visual",
            "network components",
            "virus propagation",
            "blogs",
            "approximation algorithms",
            "digital contents",
            "digital media",
            "network structures",
            "information diffusion",
            "communication networks",
            "user information",
            "approximation scheme",
            "social networks",
            "network architecture",
            "mesh network",
            "micro-blog",
            "multimedia contents",
            "optimization problems",
            "polynomial approximation",
            "wireless mesh networks (wmn)",
            "graph theory",
            "multimedia services",
            "twitter",
            "recommender systems",
            "multimedia systems",
            "world wide web",
            "communication",
            "digital rights management",
            "personal information",
            "audio acoustics",
            "neural networks",
            "computer viruses",
            "digital storage",
            "program compilers",
            "correlation analysis",
            "face recognition",
            "approximation theory",
            "computer network",
            "network protocols",
            "telecommunication networks"
        ],
        "gold_standard": [
            "approximation theory",
            "twitter",
            "social network",
            "optimization problems",
            "social media",
            "mesh network",
            "network components",
            "approximation scheme",
            "communication networks",
            "user information",
            "computer network",
            "social networks",
            "blogs",
            "personal information",
            "network structures",
            "information diffusion",
            "micro-blog",
            "graph theory",
            "world wide web",
            "microblogging",
            "network protocols",
            "optimization",
            "virus propagation",
            "network architecture",
            "approximation algorithms"
        ],
        "skgc_topics": [
            "networks of diffusion",
            "information cascades",
            "blogs",
            "news media",
            "meme-tracking",
            "social networks",
            "information diffusion",
            "virus propagation",
            "contagions",
            "infection times",
            "approximation algorithm",
            "information flows",
            "online media",
            "core-periphery structure",
            "media sites",
            "circles of influence",
            "diffusion models",
            "influence networks",
            "network inference",
            "epidemic modeling",
            "social influence",
            "information propagation",
            "network analysis",
            "computational epidemiology",
            "viral marketing",
            "network structure",
            "media influence",
            "information spread",
            "network dynamics"
        ],
        "skgc_topics_ordered": [
            "social networks",
            "blogs",
            "information diffusion",
            "virus propagation",
            "approximation algorithm",
            "network structure",
            "news media",
            "meme-tracking",
            "contagions",
            "infection times",
            "information flows",
            "online media",
            "core-periphery structure",
            "media sites",
            "circles of influence",
            "diffusion models",
            "influence networks",
            "network inference",
            "epidemic modeling",
            "social influence",
            "information propagation",
            "network analysis",
            "computational epidemiology",
            "viral marketing",
            "media influence",
            "information spread",
            "network dynamics",
            "networks of diffusion",
            "information cascades"
        ],
        "gold_standard_ordered1": [
            "social networks",
            "blogs",
            "information diffusion",
            "virus propagation",
            "approximation algorithms",
            "network structures",
            "social media",
            "mesh network",
            "network components",
            "approximation scheme",
            "communication networks",
            "user information",
            "computer network",
            "personal information",
            "micro-blog",
            "graph theory",
            "world wide web",
            "microblogging",
            "network protocols",
            "optimization",
            "network architecture",
            "approximation theory",
            "twitter",
            "optimization problems"
        ],
        "skgc_precision": 0.13793103448275862,
        "skgc_recall": 0.16666666666666666,
        "skgc_f1": 0.1509433962264151,
        "csoc_topics_ordered": [
            "approximation algorithms",
            "twitter",
            "network components",
            "approximation scheme",
            "communication networks",
            "user information",
            "social networks",
            "blogs",
            "personal information",
            "network structures",
            "information diffusion",
            "micro-blog",
            "graph theory",
            "world wide web",
            "network protocols",
            "optimization problems",
            "virus propagation",
            "network architecture",
            "approximation theory",
            "mesh network",
            "computer network",
            "social media",
            "optimization",
            "digital contents",
            "digital media",
            "neural networks",
            "multimedia contents",
            "multimedia services",
            "recommender systems",
            "wireless mesh networks (wmn)",
            "computer viruses",
            "digital storage",
            "program compilers",
            "correlation analysis",
            "face recognition",
            "telecommunication networks",
            "audio-visual",
            "digital rights management",
            "communication",
            "audio acoustics"
        ],
        "gold_standard_ordered2": [
            "approximation algorithms",
            "twitter",
            "network components",
            "approximation scheme",
            "communication networks",
            "user information",
            "social networks",
            "blogs",
            "personal information",
            "network structures",
            "information diffusion",
            "micro-blog",
            "graph theory",
            "world wide web",
            "network protocols",
            "optimization problems",
            "virus propagation",
            "network architecture",
            "approximation theory",
            "mesh network",
            "computer network",
            "social media",
            "optimization",
            "microblogging",
            "network protocols",
            "computer network",
            "social networks",
            "blogs",
            "personal information",
            "network structures",
            "information diffusion",
            "micro-blog",
            "graph theory",
            "world wide web",
            "network protocols",
            "optimization",
            "virus propagation",
            "network architecture"
        ],
        "csoc_precision": 0.55,
        "csoc_recall": 0.5789473684210527,
        "csoc_f1": 0.5641025641025641
    },
    {
        "title": "Evaluating similarity measures for emergent semantics of social tagging",
        "keywords": [
            "Social similarity",
            "semantic grounding",
            "ontology learning",
            "Web 2.0"
        ],
        "abstract": "Social bookmarking systems are becoming increasingly important data sources for bootstrapping and maintaining Semantic Web applications. Their emergent information structures have become known as folksonomies. A key question for harvesting semantics from these systems is how to extend and adapt traditional notions of similarity to folksonomies, and which measures are best suited for applications such as community detection, navigation support, semantic search, user profiling and ontology learning. Here we build an evaluation framework to compare various general folksonomy-based similarity measures, which are derived from several established information-theoretic, statistical, and practical measures. Our framework deals generally and symmetrically with users, tags, and resources. For evaluation purposes we focus on similarity between tags and between resources and consider different methods to aggregate annotations across users. After comparing the ability of several tag similarity measures to predict user-created tag relations, we provide an external grounding by user-validated semantic proxies based on WordNet and the Open Directory Project. We also investigate the issue of scalability. We find that mutual information with distributional micro-aggregation across users yields the highest accuracy, but is not scalable; per-user projection with collaborative aggregation provides the best scalable approach via incremental computations. The results are consistent across resource and tag similarity.",
        "csoc_result": [
            "semantic search",
            "wordnet",
            "microaggregation",
            "user profiling",
            "collaborative tagging",
            "mutual informations",
            "social bookmarking",
            "folksonomies",
            "web application",
            "social tagging",
            "ontology learning",
            "semantics",
            "community detection",
            "semantic web",
            "web 2.0",
            "social networks",
            "complex networks",
            "recommender systems",
            "natural language processing systems",
            "world wide web",
            "ontology",
            "personalizations",
            "metadata",
            "search engines",
            "user interfaces",
            "ontology engineering",
            "information theory",
            "k-anonymity"
        ],
        "gold_standard": [
            "collaborative tagging",
            "semantics",
            "web 2.0",
            "social bookmarking",
            "social tagging",
            "user profiling",
            "community detection",
            "wordnet",
            "semantic search",
            "folksonomies",
            "ontology matching",
            "social networks",
            "ontology engineering",
            "microaggregation",
            "ontology learning",
            "ontology",
            "semantic web"
        ],
        "skgc_topics": [
            "social tagging",
            "semantic grounding",
            "ontology learning",
            "Web 2.0",
            "social bookmarking",
            "folksonomies",
            "similarity measures",
            "community detection",
            "semantic search",
            "user profiling",
            "tag similarity",
            "mutual information",
            "scalability",
            "information retrieval",
            "semantic web",
            "collaborative filtering",
            "social network analysis",
            "knowledge discovery",
            "data mining",
            "user behavior analysis",
            "semantic similarity",
            "tag recommendation",
            "social media analysis",
            "web semantics",
            "ontology alignment",
            "user-generated content"
        ],
        "skgc_topics_ordered": [
            "social tagging",
            "Web 2.0",
            "social bookmarking",
            "folksonomies",
            "community detection",
            "semantic search",
            "user profiling",
            "ontology learning",
            "semantic web",
            "mutual information",
            "information retrieval",
            "semantic grounding",
            "similarity measures",
            "tag similarity",
            "scalability",
            "collaborative filtering",
            "social network analysis",
            "knowledge discovery",
            "data mining",
            "user behavior analysis",
            "semantic similarity",
            "tag recommendation",
            "social media analysis",
            "web semantics",
            "ontology alignment",
            "user-generated content"
        ],
        "gold_standard_ordered1": [
            "social tagging",
            "web 2.0",
            "social bookmarking",
            "folksonomies",
            "community detection",
            "semantic search",
            "user profiling",
            "ontology learning",
            "semantic web",
            "semantics",
            "wordnet",
            "ontology matching",
            "social networks",
            "ontology engineering",
            "microaggregation",
            "ontology",
            "collaborative tagging"
        ],
        "skgc_precision": 0.5769230769230769,
        "skgc_recall": 0.8823529411764706,
        "skgc_f1": 0.6976744186046512,
        "csoc_topics_ordered": [
            "social tagging",
            "web 2.0",
            "social bookmarking",
            "user profiling",
            "community detection",
            "wordnet",
            "semantic search",
            "folksonomies",
            "ontology learning",
            "semantics",
            "social networks",
            "ontology engineering",
            "microaggregation",
            "ontology",
            "collaborative tagging",
            "semantic web",
            "mutual informations",
            "web application",
            "complex networks",
            "recommender systems",
            "natural language processing systems",
            "world wide web",
            "personalizations",
            "metadata",
            "search engines",
            "user interfaces",
            "information theory",
            "k-anonymity"
        ],
        "gold_standard_ordered2": [
            "social tagging",
            "web 2.0",
            "social bookmarking",
            "user profiling",
            "community detection",
            "wordnet",
            "semantic search",
            "folksonomies",
            "ontology learning",
            "semantics",
            "social networks",
            "ontology engineering",
            "microaggregation",
            "ontology",
            "collaborative tagging",
            "semantic web",
            "ontology matching"
        ],
        "csoc_precision": 0.5714285714285714,
        "csoc_recall": 0.9411764705882353,
        "csoc_f1": 0.7111111111111111
    },
    {
        "title": "Patterns of temporal variation in online media",
        "keywords": [
            "time series clustering",
            "social media"
        ],
        "abstract": "Online content exhibits rich temporal dynamics, and diverse realtime user generated content further intensifies this process. However, temporal patterns by which online content grows and fades over time, and by which different pieces of content compete for attention remain largely unexplored.   We study temporal patterns associated with online content and how the content's popularity grows and fades over time. The attention that content receives on the Web varies depending on many factors and occurs on very different time scales and at different resolutions. In order to uncover the temporal dynamics of online content we formulate a time series clustering problem using a similarity metric that is invariant to scaling and shifting. We develop the K-Spectral Centroid ( K-SC ) clustering algorithm that effectively finds cluster centroids with our similarity measure. By applying an adaptive wavelet-based incremental approach to clustering, we scale  K-SC  to large data sets.   We demonstrate our approach on two massive datasets: a set of 580 million Tweets, and a set of 170 million blog posts and news media articles. We find that  K-SC  outperforms the K-means clustering algorithm in finding distinct shapes of time series. Our analysis shows that there are six main temporal shapes of attention of online content. We also present a simple model that reliably predicts the shape of attention by using information about only a small number of participants. Our analyses offer insight into common temporal patterns of the content on theWeb and broaden the understanding of the dynamics of human attention.",
        "csoc_result": [
            "blogs",
            "clustering algorithms",
            "digital contents",
            "social media",
            "clustering methods",
            "wavelet",
            "user-generated content",
            "k-means clustering algorithm",
            "k-means",
            "digital rights management",
            "user interfaces",
            "data mining",
            "web 2.0",
            "wavelet transforms",
            "world wide web"
        ],
        "gold_standard": [
            "data mining",
            "clustering algorithm",
            "user-generated content",
            "k-means",
            "social media",
            "clustering algorithms",
            "blogs",
            "clustering methods",
            "k-means clustering algorithm"
        ],
        "skgc_topics": [
            "time series clustering",
            "social media",
            "temporal dynamics",
            "online content",
            "temporal patterns",
            "popularity",
            "attention",
            "K-Spectral Centroid",
            "clustering algorithm",
            "wavelet-based",
            "time series",
            "K-means clustering",
            "temporal shapes",
            "human attention",
            "user generated content",
            "temporal analysis",
            "data mining",
            "big data",
            "online behavior",
            "content analysis",
            "predictive modeling",
            "web analytics",
            "social media analytics",
            "clustering techniques",
            "time series analysis",
            "adaptive algorithms",
            "wavelet transform",
            "digital media",
            "information diffusion",
            "user engagement"
        ],
        "skgc_topics_ordered": [
            "data mining",
            "clustering algorithm",
            "user generated content",
            "K-means clustering",
            "social media",
            "clustering techniques",
            "time series clustering",
            "temporal dynamics",
            "online content",
            "temporal patterns",
            "popularity",
            "attention",
            "K-Spectral Centroid",
            "wavelet-based",
            "time series",
            "temporal shapes",
            "human attention",
            "temporal analysis",
            "big data",
            "online behavior",
            "content analysis",
            "predictive modeling",
            "web analytics",
            "social media analytics",
            "time series analysis",
            "adaptive algorithms",
            "wavelet transform",
            "digital media",
            "information diffusion",
            "user engagement"
        ],
        "gold_standard_ordered1": [
            "data mining",
            "clustering algorithm",
            "user-generated content",
            "k-means",
            "social media",
            "clustering algorithms",
            "blogs",
            "clustering methods",
            "k-means clustering algorithm"
        ],
        "skgc_precision": 0.16666666666666666,
        "skgc_recall": 0.5555555555555556,
        "skgc_f1": 0.2564102564102564,
        "csoc_topics_ordered": [
            "data mining",
            "clustering algorithms",
            "user-generated content",
            "k-means",
            "social media",
            "blogs",
            "clustering methods",
            "k-means clustering algorithm",
            "wavelet",
            "digital contents",
            "digital rights management",
            "user interfaces",
            "web 2.0",
            "wavelet transforms",
            "world wide web"
        ],
        "gold_standard_ordered2": [
            "data mining",
            "clustering algorithm",
            "user-generated content",
            "k-means",
            "social media",
            "clustering algorithms",
            "blogs",
            "clustering methods",
            "k-means clustering algorithm"
        ],
        "csoc_precision": 0.6,
        "csoc_recall": 1.0,
        "csoc_f1": 0.7499999999999999
    },
    {
        "title": "A general datalog-based framework for tractable query answering over ontologies",
        "keywords": [
            "Datalog",
            "ontologies",
            "Semantic Web",
            "conjunctive queries",
            "query evaluation",
            "chase",
            "dependencies",
            "constraints",
            "complexity",
            "tractability"
        ],
        "abstract": "In this paper, we introduce a family of expressive extensions of Datalog, called Datalog+/-, as a new paradigm for query answering over ontologies. The Datalog+/- family admits existentially quantified variables in rule heads, and has suitable restrictions to ensure highly efficient ontology querying. We show in particular that Datalog+/- generalizes the DL-Lite family of tractable description logics, which are the most common tractable ontology languages in the context of the Semantic Web and databases. We also show how stratified negation can be added to Datalog+/- while keeping ontology querying tractable. Furthermore, the Datalog+/- family is of interest in its own right and can, moreover, be used in various contexts such as data integration and data exchange.",
        "csoc_result": [
            "data exchange",
            "context data",
            "ontology",
            "query answering",
            "semantic web",
            "description logic",
            "datalog",
            "ontology language",
            "database",
            "conjunctive queries",
            "data integration",
            "query evaluation",
            "data handling",
            "context information",
            "electronic data interchange",
            "query processing",
            "world wide web",
            "knowledge representation",
            "logic programming",
            "context-aware computing",
            "query languages",
            "formal languages",
            "database systems",
            "semantics",
            "formal logic"
        ],
        "gold_standard": [
            "context information",
            "formal logic",
            "query evaluation",
            "ontology",
            "logic programming",
            "data integration",
            "ontology language",
            "semantics",
            "description logic",
            "knowledge representation",
            "semantic web",
            "query languages",
            "context-aware computing",
            "conjunctive queries",
            "datalog",
            "formal languages",
            "database",
            "query answering",
            "query processing",
            "context data",
            "world wide web",
            "data exchange",
            "data handling"
        ],
        "skgc_topics": [
            "Datalog",
            "ontologies",
            "Semantic Web",
            "conjunctive queries",
            "query evaluation",
            "chase",
            "dependencies",
            "constraints",
            "complexity",
            "tractability",
            "existentially quantified variables",
            "DL-Lite",
            "description logics",
            "stratified negation",
            "data integration",
            "data exchange",
            "ontology querying",
            "query optimization",
            "data integration systems",
            "data exchange frameworks",
            "knowledge representation",
            "logic programming",
            "database theory",
            "semantic reasoning",
            "rule-based systems",
            "knowledge bases",
            "ontology languages",
            "data management",
            "information systems",
            "logical frameworks",
            "computational logic"
        ],
        "skgc_topics_ordered": [
            "Datalog",
            "query evaluation",
            "ontologies",
            "Semantic Web",
            "conjunctive queries",
            "data integration",
            "description logics",
            "logic programming",
            "knowledge representation",
            "data exchange",
            "ontology languages",
            "query optimization",
            "ontology querying",
            "data integration systems",
            "data exchange frameworks",
            "semantic reasoning",
            "rule-based systems",
            "knowledge bases",
            "data management",
            "information systems",
            "logical frameworks",
            "computational logic",
            "chase",
            "dependencies",
            "constraints",
            "complexity",
            "tractability",
            "existentially quantified variables",
            "DL-Lite",
            "stratified negation",
            "database theory"
        ],
        "gold_standard_ordered1": [
            "Datalog",
            "query evaluation",
            "ontology",
            "semantic web",
            "conjunctive queries",
            "data integration",
            "description logic",
            "logic programming",
            "knowledge representation",
            "data exchange",
            "ontology language",
            "query answering",
            "context information",
            "formal logic",
            "semantics",
            "query languages",
            "context-aware computing",
            "formal languages",
            "database",
            "query processing",
            "context data",
            "world wide web",
            "data handling"
        ],
        "skgc_precision": 0.5161290322580645,
        "skgc_recall": 0.6956521739130435,
        "skgc_f1": 0.5925925925925926,
        "csoc_topics_ordered": [
            "query evaluation",
            "ontology",
            "semantic web",
            "description logic",
            "datalog",
            "ontology language",
            "conjunctive queries",
            "data integration",
            "query answering",
            "context information",
            "formal logic",
            "knowledge representation",
            "logic programming",
            "context-aware computing",
            "query languages",
            "formal languages",
            "database",
            "query processing",
            "context data",
            "world wide web",
            "data exchange",
            "data handling",
            "database systems",
            "semantics",
            "electronic data interchange"
        ],
        "gold_standard_ordered2": [
            "query evaluation",
            "ontology",
            "semantic web",
            "description logic",
            "datalog",
            "ontology language",
            "conjunctive queries",
            "data integration",
            "query answering",
            "context information",
            "formal logic",
            "knowledge representation",
            "logic programming",
            "context-aware computing",
            "query languages",
            "formal languages",
            "database",
            "query processing",
            "context data",
            "world wide web",
            "data exchange",
            "data handling",
            "semantics",
            "formal logic"
        ],
        "csoc_precision": 1.0,
        "csoc_recall": 1.0416666666666667,
        "csoc_f1": 1.0204081632653061
    },
    {
        "title": "A holistic lexicon-based approach to opinion mining",
        "keywords": [
            "opinion mining",
            "context dependent opinions",
            "sentiment analysis"
        ],
        "abstract": "One of the important types of information on the Web is the opinions expressed in the user generated content, e.g., customer reviews of products, forum posts, and blogs. In this paper, we focus on customer reviews of products. In particular, we study the problem of determining the semantic orientations (positive, negative or neutral) of opinions expressed on product features in reviews. This problem has many applications, e.g., opinion mining, summarization and search. Most existing techniques utilize a list of  opinion (bearing) words  (also called  opinion  lexicon) for the purpose. Opinion words are words that express desirable (e.g., great, amazing, etc.) or undesirable (e.g., bad, poor, etc) states. These approaches, however, all have some major shortcomings. In this paper, we propose a  holistic lexicon-based approach  to solving the problem by exploiting external evidences and linguistic conventions of natural language expressions. This approach allows the system to handle opinion words that are context dependent, which cause major difficulties for existing algorithms. It also deals with many special words, phrases and language constructs which have impacts on opinions based on their linguistic patterns. It also has an effective function for aggregating multiple conflicting opinion words in a sentence. A system, called Opinion Observer, based on the proposed technique has been implemented. Experimental results using a benchmark product review data set and some additional reviews show that the proposed technique is highly effective. It outperforms existing methods significantly",
        "csoc_result": [
            "opinion mining",
            "product feature",
            "natural languages",
            "blogs",
            "observer",
            "linguistics",
            "sentiment classification",
            "customer review",
            "part of speech",
            "sentiment analysis",
            "polarity classification",
            "user-generated content",
            "product reviews",
            "semantic orientation",
            "languages",
            "computer programming languages",
            "electronic commerce",
            "natural language processing",
            "web 2.0",
            "sales",
            "object oriented programming",
            "natural language processing systems",
            "world wide web",
            "observability",
            "computational linguistics",
            "social media",
            "text processing",
            "user interfaces",
            "data mining",
            "query languages",
            "semantics"
        ],
        "gold_standard": [
            "opinion mining",
            "semantics",
            "product reviews",
            "data mining",
            "computational linguistics",
            "information retrieval",
            "semantic orientation",
            "customer review",
            "user-generated content",
            "sentiment analysis",
            "social media",
            "linguistics",
            "sales",
            "blogs",
            "natural language processing systems"
        ],
        "skgc_topics": [
            "opinion mining",
            "sentiment analysis",
            "customer reviews",
            "semantic orientations",
            "opinion lexicon",
            "opinion words",
            "linguistic conventions",
            "natural language expressions",
            "context dependent",
            "product features",
            "Opinion Observer",
            "sentiment classification",
            "opinion summarization",
            "text analysis",
            "product reviews",
            "opinion aggregation",
            "natural language processing",
            "context-aware sentiment analysis",
            "opinion extraction",
            "review analysis"
        ],
        "skgc_topics_ordered": [
            "opinion mining",
            "sentiment analysis",
            "customer reviews",
            "product reviews",
            "semantic orientations",
            "opinion lexicon",
            "opinion words",
            "linguistic conventions",
            "natural language expressions",
            "context dependent",
            "Opinion Observer",
            "sentiment classification",
            "opinion summarization",
            "text analysis",
            "opinion aggregation",
            "natural language processing",
            "context-aware sentiment analysis",
            "opinion extraction",
            "review analysis",
            "product features"
        ],
        "gold_standard_ordered1": [
            "opinion mining",
            "sentiment analysis",
            "customer review",
            "product reviews",
            "semantic orientation",
            "semantics",
            "computational linguistics",
            "information retrieval",
            "user-generated content",
            "social media",
            "linguistics",
            "sales",
            "blogs",
            "natural language processing systems",
            "data mining"
        ],
        "skgc_precision": 0.5,
        "skgc_recall": 0.6666666666666666,
        "skgc_f1": 0.5714285714285715,
        "csoc_topics_ordered": [
            "opinion mining",
            "sentiment analysis",
            "product reviews",
            "semantic orientation",
            "customer review",
            "user-generated content",
            "social media",
            "linguistics",
            "blogs",
            "natural language processing systems",
            "semantics",
            "data mining",
            "computational linguistics",
            "sentiment classification",
            "product feature",
            "natural languages",
            "observer",
            "part of speech",
            "polarity classification",
            "languages",
            "computer programming languages",
            "electronic commerce",
            "natural language processing",
            "web 2.0",
            "sales",
            "object oriented programming",
            "world wide web",
            "observability",
            "text processing",
            "user interfaces",
            "query languages"
        ],
        "gold_standard_ordered2": [
            "opinion mining",
            "sentiment analysis",
            "product reviews",
            "semantic orientation",
            "customer review",
            "user-generated content",
            "social media",
            "linguistics",
            "blogs",
            "natural language processing systems",
            "semantics",
            "data mining",
            "computational linguistics",
            "information retrieval",
            "sales"
        ],
        "csoc_precision": 0.45161290322580644,
        "csoc_recall": 0.9333333333333333,
        "csoc_f1": 0.608695652173913
    },
    {
        "title": "Hive - a petabyte scale data warehouse using Hadoop",
        "keywords": [
            "competitive intelligence",
            "data warehouses",
            "public domain software",
            "query processing",
            "SQL"
        ],
        "abstract": "The size of data sets being collected and analyzed in the industry for business intelligence is growing rapidly, making traditional warehousing solutions prohibitively expensive. Hadoop [1] is a popular open-source map-reduce implementation which is being used in companies like Yahoo, Facebook etc. to store and process extremely large data sets on commodity hardware. However, the map-reduce programming model is very low level and requires developers to write custom programs which are hard to maintain and reuse. In this paper, we present Hive, an open-source data warehousing solution built on top of Hadoop. Hive supports queries expressed in a SQL-like declarative language - HiveQL, which are compiled into map-reduce jobs that are executed using Hadoop. In addition, HiveQL enables users to plug in custom map-reduce scripts into queries. The language includes a type system with support for tables containing primitive types, collections like arrays and maps, and nested compositions of the same. The underlying IO libraries can be extended to query data in custom formats. Hive also includes a system catalog - Metastore - that contains schemas and statistics, which are useful in data exploration, query optimization and query compilation. In Facebook, the Hive warehouse contains tens of thousands of tables and stores over 700TB of data and is being used extensively for both reporting and ad-hoc analyses by more than 200 users per month.",
        "csoc_result": [
            "facebook",
            "query optimization",
            "type systems",
            "sql",
            "computer hardware",
            "sql query",
            "query results",
            "query processing",
            "programming models",
            "languages",
            "libraries",
            "software",
            "hadoop",
            "correlation analysis",
            "business intelligence",
            "map-reduce",
            "data warehousing",
            "competitive intelligence",
            "data warehouses",
            "warehouses",
            "computer programming languages",
            "data handling",
            "information management",
            "parallel programming",
            "linguistics",
            "strategic planning",
            "social networks",
            "object oriented programming",
            "pattern",
            "education",
            "mathematics",
            "cloud computing",
            "computer science",
            "search engines",
            "data mining",
            "program compilers",
            "relational database",
            "query languages",
            "database systems",
            "information systems"
        ],
        "gold_standard": [
            "query optimization",
            "information management",
            "business intelligence",
            "warehouses",
            "relational database",
            "query languages",
            "query results",
            "data warehouses",
            "correlation analysis",
            "database systems",
            "map-reduce",
            "data warehousing",
            "facebook",
            "query processing",
            "optimization",
            "software",
            "hadoop"
        ],
        "skgc_topics": [
            "data warehouses",
            "Hadoop",
            "map-reduce",
            "Hive",
            "SQL",
            "HiveQL",
            "Metastore",
            "data exploration",
            "query optimization",
            "query compilation",
            "business intelligence",
            "open-source",
            "type system",
            "tables",
            "collections",
            "schemas",
            "statistics",
            "big data",
            "distributed computing",
            "data processing",
            "data management",
            "cloud computing",
            "data analytics",
            "ETL (Extract",
            "Transform",
            "Load)",
            "data integration",
            "data storage",
            "data querying",
            "data warehousing solutions",
            "business analytics",
            "data mining",
            "scalable systems",
            "high-performance computing"
        ],
        "skgc_topics_ordered": [
            "data warehouses",
            "Hadoop",
            "map-reduce",
            "business intelligence",
            "query optimization",
            "data warehousing solutions",
            "query compilation",
            "data exploration",
            "data processing",
            "data management",
            "data analytics",
            "data integration",
            "data storage",
            "data querying",
            "data mining",
            "Hive",
            "SQL",
            "HiveQL",
            "Metastore",
            "open-source",
            "type system",
            "tables",
            "collections",
            "schemas",
            "statistics",
            "big data",
            "distributed computing",
            "cloud computing",
            "ETL (Extract",
            "Transform",
            "Load)",
            "business analytics",
            "scalable systems",
            "high-performance computing"
        ],
        "gold_standard_ordered1": [
            "data warehouses",
            "Hadoop",
            "map-reduce",
            "business intelligence",
            "query optimization",
            "data warehousing",
            "query processing",
            "query results",
            "information management",
            "warehouses",
            "relational database",
            "query languages",
            "correlation analysis",
            "database systems",
            "optimization",
            "software",
            "facebook"
        ],
        "skgc_precision": 0.47058823529411764,
        "skgc_recall": 0.9411764705882353,
        "skgc_f1": 0.627450980392157,
        "csoc_topics_ordered": [
            "query optimization",
            "information management",
            "business intelligence",
            "data warehouses",
            "warehouses",
            "relational database",
            "query languages",
            "query results",
            "correlation analysis",
            "database systems",
            "map-reduce",
            "data warehousing",
            "facebook",
            "query processing",
            "software",
            "hadoop",
            "cloud computing",
            "data mining",
            "sql",
            "sql query",
            "programming models",
            "languages",
            "libraries",
            "type systems",
            "computer hardware",
            "competitive intelligence",
            "computer programming languages",
            "data handling",
            "parallel programming",
            "linguistics",
            "strategic planning",
            "social networks",
            "object oriented programming",
            "pattern",
            "education",
            "mathematics",
            "computer science",
            "search engines",
            "program compilers",
            "information systems"
        ],
        "gold_standard_ordered2": [
            "query optimization",
            "information management",
            "business intelligence",
            "warehouses",
            "relational database",
            "query languages",
            "query results",
            "data warehouses",
            "correlation analysis",
            "database systems",
            "map-reduce",
            "data warehousing",
            "facebook",
            "query processing",
            "optimization",
            "software",
            "hadoop"
        ],
        "csoc_precision": 0.4,
        "csoc_recall": 0.9411764705882353,
        "csoc_f1": 0.5614035087719298
    },
    {
        "title": "Collaborative filtering with temporal dynamics",
        "keywords": [
            "collaborative filtering",
            "recommender systems",
            "concept drift"
        ],
        "abstract": "Customer preferences for products are drifting over time. Product perception and popularity are constantly changing as new selection emerges. Similarly, customer inclinations are evolving, leading them to ever redefine their taste. Thus, modeling temporal dynamics should be a key when designing recommender systems or general customer preference models. However, this raises unique challenges. Within the eco-system intersecting multiple products and customers, many different characteristics are shifting simultaneously, while many of them influence each other and often those shifts are delicate and associated with a few data instances. This distinguishes the problem from concept drift explorations, where mostly a single concept is tracked. Classical time-window or instance-decay approaches cannot work, as they lose too much signal when discarding data instances. A more sensitive approach is required, which can make better distinctions between transient effects and long term patterns. The paradigm we offer is creating a model tracking the time changing behavior throughout the life span of the data. This allows us to exploit the relevant components of all data instances, while discarding only what is modeled as being irrelevant. Accordingly, we revamp two leading collaborative filtering recommendation approaches. Evaluation is made on a large movie rating dataset by Netflix. Results are encouraging and better than those previously reported on this dataset.",
        "csoc_result": [
            "recommendation",
            "distinguishers",
            "collaborative filtering",
            "recommender systems",
            "concept drifts",
            "component",
            "software",
            "cryptanalysis",
            "data stream",
            "block ciphers",
            "information retrieval",
            "hash functions"
        ],
        "gold_standard": [
            "recommender systems",
            "collaborative filtering",
            "hybrid recommender systems",
            "concept drifts",
            "information retrieval",
            "recommendation"
        ],
        "skgc_topics": [
            "collaborative filtering",
            "temporal dynamics",
            "recommender systems",
            "concept drift",
            "customer preferences",
            "product perception",
            "popularity",
            "customer inclinations",
            "transient effects",
            "long term patterns",
            "movie rating dataset",
            "Netflix",
            "recommendation systems",
            "user behavior",
            "time series analysis",
            "dynamic modeling",
            "personalized recommendations",
            "data-driven models",
            "customer behavior analysis",
            "adaptive algorithms",
            "preference evolution",
            "recommendation algorithms",
            "collaborative filtering techniques"
        ],
        "skgc_topics_ordered": [
            "recommender systems",
            "collaborative filtering",
            "concept drift",
            "recommendation systems",
            "recommendation algorithms",
            "collaborative filtering techniques",
            "temporal dynamics",
            "customer preferences",
            "product perception",
            "popularity",
            "customer inclinations",
            "transient effects",
            "long term patterns",
            "movie rating dataset",
            "Netflix",
            "user behavior",
            "time series analysis",
            "dynamic modeling",
            "personalized recommendations",
            "data-driven models",
            "customer behavior analysis",
            "adaptive algorithms",
            "preference evolution"
        ],
        "gold_standard_ordered1": [
            "recommender systems",
            "collaborative filtering",
            "concept drifts",
            "hybrid recommender systems",
            "information retrieval",
            "recommendation"
        ],
        "skgc_precision": 0.2608695652173913,
        "skgc_recall": 1.0,
        "skgc_f1": 0.41379310344827586,
        "csoc_topics_ordered": [
            "recommendation",
            "collaborative filtering",
            "recommender systems",
            "concept drifts",
            "information retrieval",
            "distinguishers",
            "component",
            "software",
            "cryptanalysis",
            "data stream",
            "block ciphers",
            "hash functions"
        ],
        "gold_standard_ordered2": [
            "recommendation",
            "collaborative filtering",
            "recommender systems",
            "concept drifts",
            "information retrieval",
            "hybrid recommender systems"
        ],
        "csoc_precision": 0.4166666666666667,
        "csoc_recall": 0.8333333333333334,
        "csoc_f1": 0.5555555555555556
    },
    {
        "title": "Visual Madlibs: Fill in the Blank Description Generation and Question Answering",
        "keywords": [
            "image retrieval",
            "natural language processing",
            "question answering (information retrieval)"
        ],
        "abstract": "In this paper, we introduce a new dataset consisting of 360,001 focused natural language descriptions for 10,738 images. This dataset, the Visual Madlibs dataset, is collected using automatically produced fill-in-the-blank templates designed to gather targeted descriptions about: people and objects, their appearances, activities, and interactions, as well as inferences about the general scene or its broader context. We provide several analyses of the Visual Madlibs dataset and demonstrate its applicability to two new description generation tasks: focused description generation, and multiple-choice question-answering for images. Experiments using joint-embedding and deep learning methods show promising results on these tasks.",
        "csoc_result": [
            "image retrieval",
            "digital image",
            "reference image",
            "natural languages",
            "embeddings",
            "color images",
            "deep learning",
            "inference",
            "information retrieval",
            "natural language processing",
            "question answering",
            "natural language understanding",
            "object appearance",
            "natural language text",
            "linguistics",
            "speech recognition",
            "image enhancement",
            "image quality",
            "inference engines",
            "natural language processing systems",
            "pattern recognition",
            "image processing",
            "image analysis",
            "image segmentation",
            "computer science",
            "computational linguistics",
            "knowledge representation",
            "neural networks",
            "image matching",
            "planar graph",
            "database systems",
            "object tracking",
            "semantics",
            "color image processing"
        ],
        "gold_standard": [
            "image processing",
            "image analysis",
            "deep learning",
            "natural language processing",
            "image retrieval",
            "knowledge representation",
            "information retrieval",
            "computer science",
            "digital image",
            "question answering",
            "natural language text"
        ],
        "skgc_topics": [
            "image retrieval",
            "natural language processing",
            "question answering",
            "description generation",
            "dataset",
            "images",
            "deep learning",
            "joint-embedding",
            "fill-in-the-blank",
            "multiple-choice question-answering",
            "visual question answering",
            "computer vision",
            "image description",
            "scene understanding",
            "natural language generation",
            "visual datasets",
            "image analysis",
            "machine learning",
            "artificial intelligence",
            "visual recognition",
            "image annotation"
        ],
        "skgc_topics_ordered": [
            "image retrieval",
            "natural language processing",
            "question answering",
            "deep learning",
            "image analysis",
            "computer vision",
            "description generation",
            "dataset",
            "images",
            "joint-embedding",
            "fill-in-the-blank",
            "multiple-choice question-answering",
            "visual question answering",
            "image description",
            "scene understanding",
            "natural language generation",
            "visual datasets",
            "machine learning",
            "artificial intelligence",
            "visual recognition",
            "image annotation"
        ],
        "gold_standard_ordered1": [
            "image retrieval",
            "natural language processing",
            "question answering",
            "deep learning",
            "image analysis",
            "image processing",
            "knowledge representation",
            "information retrieval",
            "computer science",
            "digital image",
            "natural language text"
        ],
        "skgc_precision": 0.47619047619047616,
        "skgc_recall": 0.9090909090909091,
        "skgc_f1": 0.6249999999999999,
        "csoc_topics_ordered": [
            "image retrieval",
            "digital image",
            "deep learning",
            "natural language processing",
            "question answering",
            "image analysis",
            "image processing",
            "knowledge representation",
            "information retrieval",
            "computer science",
            "natural language text",
            "reference image",
            "natural languages",
            "embeddings",
            "color images",
            "inference",
            "natural language understanding",
            "object appearance",
            "linguistics",
            "speech recognition",
            "image enhancement",
            "image quality",
            "inference engines",
            "natural language processing systems",
            "pattern recognition",
            "image segmentation",
            "computational linguistics",
            "neural networks",
            "image matching",
            "planar graph",
            "database systems",
            "object tracking",
            "semantics",
            "color image processing"
        ],
        "gold_standard_ordered2": [
            "image retrieval",
            "digital image",
            "deep learning",
            "natural language processing",
            "question answering",
            "image analysis",
            "image processing",
            "knowledge representation",
            "information retrieval",
            "computer science",
            "natural language text"
        ],
        "csoc_precision": 0.3235294117647059,
        "csoc_recall": 1.0,
        "csoc_f1": 0.48888888888888893
    },
    {
        "title": "Bayesian probabilistic matrix factorization using Markov chain Monte Carlo",
        "keywords": [],
        "abstract": "Low-rank matrix approximation methods provide one of the simplest and most effective approaches to collaborative filtering. Such models are usually fitted to data by finding a MAP estimate of the model parameters, a procedure that can be performed efficiently even on very large datasets. However, unless the regularization parameters are tuned carefully, this approach is prone to overfitting because it finds a single point estimate of the parameters. In this paper we present a fully Bayesian treatment of the Probabilistic Matrix Factorization (PMF) model in which model capacity is controlled automatically by integrating over all model parameters and hyperparameters. We show that Bayesian PMF models can be efficiently trained using Markov chain Monte Carlo methods by applying them to the Netflix dataset, which consists of over 100 million movie ratings. The resulting models achieve significantly higher prediction accuracy than PMF models trained using MAP estimation.",
        "csoc_result": [
            "bayesian inference",
            "factorization",
            "bayesian",
            "collaborative filtering",
            "regularization",
            "approximation methods",
            "matrix factorizations",
            "regularization parameters",
            "markov chains",
            "matrix algebra",
            "image reconstruction",
            "markov processes",
            "inference engines",
            "bayes theorem",
            "approximation theory",
            "recommender systems",
            "parameterization",
            "bayesian networks",
            "inverse problems"
        ],
        "gold_standard": [
            "recommender systems",
            "collaborative filtering",
            "matrix factorizations",
            "bayesian networks",
            "markov chain monte carlo",
            "approximation methods",
            "markov processes",
            "factorization",
            "markov chains",
            "bayesian",
            "bayesian inference",
            "bayes theorem"
        ],
        "skgc_topics": [
            "collaborative filtering",
            "low-rank matrix approximation",
            "Bayesian treatment",
            "probabilistic matrix factorization",
            "Markov chain Monte Carlo",
            "Netflix dataset",
            "prediction accuracy",
            "Bayesian inference",
            "machine learning",
            "movie recommendation",
            "MAP estimation",
            "hyperparameter tuning",
            "overfitting prevention",
            "data sparsity",
            "model capacity",
            "collaborative filtering techniques",
            "recommendation systems",
            "Bayesian methods",
            "matrix factorization techniques"
        ],
        "skgc_topics_ordered": [
            "collaborative filtering",
            "Bayesian inference",
            "collaborative filtering techniques",
            "probabilistic matrix factorization",
            "Markov chain Monte Carlo",
            "Bayesian treatment",
            "low-rank matrix approximation",
            "matrix factorization techniques",
            "Netflix dataset",
            "prediction accuracy",
            "machine learning",
            "movie recommendation",
            "MAP estimation",
            "hyperparameter tuning",
            "overfitting prevention",
            "data sparsity",
            "model capacity",
            "Bayesian methods",
            "recommendation systems"
        ],
        "gold_standard_ordered1": [
            "collaborative filtering",
            "Bayesian inference",
            "collaborative filtering techniques",
            "matrix factorizations",
            "markov chain monte carlo",
            "bayesian networks",
            "approximation methods",
            "markov processes",
            "Netflix dataset",
            "prediction accuracy",
            "machine learning",
            "movie recommendation",
            "MAP estimation",
            "hyperparameter tuning",
            "overfitting prevention",
            "data sparsity",
            "model capacity",
            "Bayesian methods",
            "recommendation systems"
        ],
        "skgc_precision": 1.0,
        "skgc_recall": 1.0,
        "skgc_f1": 1.0,
        "csoc_topics_ordered": [
            "bayesian inference",
            "collaborative filtering",
            "matrix factorizations",
            "bayesian networks",
            "approximation methods",
            "markov chains",
            "bayesian",
            "bayes theorem",
            "factorization",
            "recommender systems",
            "regularization",
            "approximation theory",
            "markov processes",
            "matrix algebra",
            "image reconstruction",
            "inference engines",
            "regularization parameters",
            "parameterization",
            "inverse problems"
        ],
        "gold_standard_ordered2": [
            "bayesian inference",
            "collaborative filtering",
            "matrix factorizations",
            "bayesian networks",
            "approximation methods",
            "markov chains",
            "bayesian",
            "bayes theorem",
            "factorization",
            "recommender systems",
            "markov chain monte carlo",
            "approximation methods",
            "markov processes"
        ],
        "csoc_precision": 0.5263157894736842,
        "csoc_recall": 0.7692307692307693,
        "csoc_f1": 0.625
    },
    {
        "title": "The spoofax language workbench: rules for declarative specification of languages and IDEs",
        "keywords": [],
        "abstract": "Spoofax is a language workbench for efficient, agile development of textual domain-specific languages with state-of-the-art IDE support. Spoofax integrates language processing techniques for parser generation, meta-programming, and IDE development into a single environment. It uses concise, declarative specifications for languages and IDE services. In this paper we describe the architecture of Spoofax and introduce idioms for high-level specifications of language semantics using rewrite rules, showing how analyses can be reused for transformations, code generation, and editor services such as error marking, reference resolving, and content completion. The implementation of these services is supported by language-parametric editor service classes that can be dynamically loaded by the Eclipse IDE, allowing new languages to be developed and used side-by-side in the same Eclipse environment.",
        "csoc_result": [
            "meta programming",
            "programming languages",
            "code generation",
            "semantics",
            "agile methods",
            "languages",
            "functional programming",
            "computer programming languages",
            "agile software development",
            "linguistics",
            "computer systems programming",
            "logic programming",
            "program compilers",
            "software development",
            "query languages",
            "object oriented programming"
        ],
        "gold_standard": [
            "agile methods",
            "programming language",
            "software development",
            "code generation",
            "languages",
            "meta programming",
            "agile software development",
            "programming languages"
        ],
        "skgc_topics": [
            "language workbench",
            "domain-specific languages",
            "IDE support",
            "parser generation",
            "meta-programming",
            "rewrite rules",
            "code generation",
            "editor services",
            "error marking",
            "reference resolving",
            "content completion",
            "Eclipse IDE",
            "language development",
            "textual languages",
            "language semantics",
            "language processing",
            "software development tools",
            "agile development",
            "domain-specific language tools",
            "integrated development environment",
            "language specification",
            "language transformation",
            "syntax analysis",
            "semantic analysis",
            "software engineering",
            "programming languages",
            "language engineering",
            "software tools",
            "language integration",
            "Eclipse plugins"
        ],
        "skgc_topics_ordered": [
            "programming languages",
            "code generation",
            "meta-programming",
            "language workbench",
            "domain-specific languages",
            "IDE support",
            "parser generation",
            "rewrite rules",
            "editor services",
            "error marking",
            "reference resolving",
            "content completion",
            "Eclipse IDE",
            "language development",
            "textual languages",
            "language semantics",
            "language processing",
            "software development tools",
            "agile development",
            "domain-specific language tools",
            "integrated development environment",
            "language specification",
            "language transformation",
            "syntax analysis",
            "semantic analysis",
            "software engineering",
            "language engineering",
            "software tools",
            "language integration",
            "Eclipse plugins"
        ],
        "gold_standard_ordered1": [
            "programming languages",
            "code generation",
            "meta programming",
            "agile methods",
            "software development",
            "languages",
            "agile software development",
            "programming language"
        ],
        "skgc_precision": 0.23333333333333334,
        "skgc_recall": 0.875,
        "skgc_f1": 0.3684210526315789,
        "csoc_topics_ordered": [
            "programming languages",
            "code generation",
            "meta programming",
            "agile methods",
            "languages",
            "agile software development",
            "software development",
            "semantics",
            "functional programming",
            "computer programming languages",
            "linguistics",
            "computer systems programming",
            "logic programming",
            "program compilers",
            "query languages",
            "object oriented programming"
        ],
        "gold_standard_ordered2": [
            "programming languages",
            "code generation",
            "meta programming",
            "agile methods",
            "languages",
            "agile software development",
            "software development",
            "programming language"
        ],
        "csoc_precision": 0.5,
        "csoc_recall": 1.0,
        "csoc_f1": 0.6666666666666666
    },
    {
        "title": "The two cultures: mashing up web 2.0 and the semantic web",
        "keywords": [
            "blog",
            "web 2 0",
            "semantic web",
            "vision",
            "rdf"
        ],
        "abstract": "A common perception is that there are two competing visions for the future evolution of the Web: the Semantic Web and Web 2.0. A closer look, though, reveals that the core technologies and concerns of these two approaches are complementary and that each field can and must draw from the other's strengths. We believe that future web applications will retain the Web 2.0 focus on community and usability, while drawing on Semantic Web infrastructure to facilitate mashup-like information sharing. However, there are several open issues that must be addressed before such applications can become commonplace. In this paper, we outline a semantic weblogs scenario that illustrates the potential for combining Web 2.0 and Semantic Web technologies, while highlighting the unresolved issues that impede its realization. Nevertheless, we believe that the scenario can be realized in the short-term. We point to recent progress made in resolving each of the issues as well as future research directions for each of the communities.",
        "csoc_result": [
            "web information",
            "weblogs",
            "ajax",
            "blogs",
            "information sharing",
            "mashup",
            "semantic web",
            "web application",
            "rdf",
            "semantics",
            "world wide web",
            "information management",
            "javascript",
            "linguistics",
            "bloggers",
            "search engines",
            "information dissemination",
            "user interfaces",
            "internet",
            "information analysis",
            "web 2.0",
            "resource description framework",
            "information technology"
        ],
        "gold_standard": [
            "weblogs",
            "semantics",
            "web 2.0",
            "world wide web",
            "web information",
            "internet",
            "resource description framework",
            "semantic web",
            "blogs",
            "rdf"
        ],
        "skgc_topics": [
            "web 2.0",
            "semantic web",
            "mashup",
            "information sharing",
            "semantic weblogs",
            "community",
            "usability",
            "infrastructure",
            "unresolved issues",
            "future research directions",
            "rdf",
            "blog",
            "web technologies",
            "semantic technologies",
            "web evolution",
            "social media",
            "data integration",
            "interoperability",
            "web applications",
            "semantic integration",
            "web standards"
        ],
        "skgc_topics_ordered": [
            "web 2.0",
            "semantic web",
            "rdf",
            "blog",
            "semantic weblogs",
            "community",
            "usability",
            "infrastructure",
            "unresolved issues",
            "future research directions",
            "mashup",
            "information sharing",
            "web technologies",
            "semantic technologies",
            "web evolution",
            "social media",
            "data integration",
            "interoperability",
            "web applications",
            "semantic integration",
            "web standards"
        ],
        "gold_standard_ordered1": [
            "web 2.0",
            "semantic web",
            "rdf",
            "blogs",
            "weblogs",
            "semantics",
            "world wide web",
            "web information",
            "internet",
            "resource description framework"
        ],
        "skgc_precision": 0.2857142857142857,
        "skgc_recall": 0.6,
        "skgc_f1": 0.3870967741935483,
        "csoc_topics_ordered": [
            "web 2.0",
            "semantics",
            "world wide web",
            "web information",
            "resource description framework",
            "semantic web",
            "blogs",
            "rdf",
            "weblogs",
            "information sharing",
            "mashup",
            "web application",
            "information management",
            "javascript",
            "ajax",
            "bloggers",
            "search engines",
            "information dissemination",
            "user interfaces",
            "internet",
            "information analysis",
            "information technology",
            "linguistics"
        ],
        "gold_standard_ordered2": [
            "web 2.0",
            "semantics",
            "world wide web",
            "web information",
            "resource description framework",
            "semantic web",
            "blogs",
            "rdf",
            "weblogs",
            "internet"
        ],
        "csoc_precision": 0.43478260869565216,
        "csoc_recall": 1.0,
        "csoc_f1": 0.6060606060606061
    },
    {
        "title": "Exploiting Wikipedia as external knowledge for document clustering",
        "keywords": [
            "Text Clustering",
            "Wikipedia",
            "Document Representation"
        ],
        "abstract": "In traditional text clustering methods, documents are represented as \"bags of words\" without considering the semantic information of each document. For instance, if two documents use different collections of core words to represent the same topic, they may be falsely assigned to different clusters due to the lack of shared core words, although the core words they use are probably synonyms or semantically associated in other forms. The most common way to solve this problem is to enrich document representation with the background knowledge in an ontology. There are two major issues for this approach: (1) the coverage of the ontology is limited, even for WordNet or Mesh, (2) using ontology terms as replacement or additional features may cause information loss, or introduce noise. In this paper, we present a novel text clustering method to address these two issues by enriching document representation with Wikipedia concept and category information. We develop two approaches, exact match and relatedness-match, to map text documents to Wikipedia concepts, and further to Wikipedia categories. Then the text documents are clustered based on a similarity metric which combines document content information, concept information as well as category information. The experimental results using the proposed clustering framework on three datasets (20-newsgroup, TDT2, and LA Times) show that clustering performance improves significantly by enriching document representation with Wikipedia concepts and categories.",
        "csoc_result": [
            "semantic information",
            "wordnet",
            "text document",
            "clustering algorithms",
            "context information",
            "clustering methods",
            "document representation",
            "background knowledge",
            "document clustering",
            "information loss",
            "text clustering",
            "ontology",
            "text mining",
            "data privacy",
            "information retrieval",
            "text processing",
            "knowledge representation",
            "data mining",
            "cluster analysis",
            "context-awareness",
            "information retrieval systems",
            "natural language processing systems",
            "semantics"
        ],
        "gold_standard": [
            "semantic information",
            "computational linguistics",
            "information retrieval",
            "cluster analysis",
            "knowledge representation",
            "text mining",
            "text processing",
            "document classification",
            "text clustering",
            "text document",
            "clustering methods",
            "natural language processing systems",
            "information retrieval systems",
            "wordnet",
            "background knowledge",
            "clustering algorithms",
            "text classification"
        ],
        "skgc_topics": [
            "text clustering",
            "Wikipedia",
            "document representation",
            "semantic information",
            "ontology",
            "Wikipedia concept",
            "Wikipedia category",
            "similarity metric",
            "clustering performance",
            "document clustering",
            "knowledge representation",
            "semantic clustering",
            "information retrieval",
            "text mining",
            "unsupervised learning",
            "data mining",
            "natural language processing",
            "machine learning",
            "concept mapping"
        ],
        "skgc_topics_ordered": [
            "text clustering",
            "semantic information",
            "information retrieval",
            "knowledge representation",
            "text mining",
            "natural language processing",
            "Wikipedia",
            "document representation",
            "Wikipedia concept",
            "Wikipedia category",
            "similarity metric",
            "clustering performance",
            "document clustering",
            "semantic clustering",
            "unsupervised learning",
            "data mining",
            "machine learning",
            "concept mapping"
        ],
        "gold_standard_ordered1": [
            "text clustering",
            "semantic information",
            "information retrieval",
            "knowledge representation",
            "text mining",
            "natural language processing systems",
            "computational linguistics",
            "cluster analysis",
            "text processing",
            "document classification",
            "text document",
            "clustering methods",
            "information retrieval systems",
            "wordnet",
            "background knowledge",
            "clustering algorithms",
            "text classification"
        ],
        "skgc_precision": 0.6666666666666666,
        "skgc_recall": 0.7058823529411765,
        "skgc_f1": 0.6857142857142857,
        "csoc_topics_ordered": [
            "semantic information",
            "wordnet",
            "text document",
            "clustering algorithms",
            "clustering methods",
            "document representation",
            "background knowledge",
            "document clustering",
            "text clustering",
            "ontology",
            "text mining",
            "information retrieval",
            "text processing",
            "knowledge representation",
            "data mining",
            "cluster analysis",
            "information retrieval systems",
            "natural language processing systems",
            "semantics",
            "context information",
            "information loss",
            "data privacy",
            "context-awareness"
        ],
        "gold_standard_ordered2": [
            "semantic information",
            "wordnet",
            "text document",
            "clustering algorithms",
            "clustering methods",
            "document classification",
            "background knowledge",
            "text clustering",
            "text mining",
            "information retrieval",
            "text processing",
            "knowledge representation",
            "computational linguistics",
            "cluster analysis",
            "information retrieval systems",
            "natural language processing systems",
            "semantics",
            "text classification"
        ],
        "csoc_precision": 0.782608695652174,
        "csoc_recall": 1.0,
        "csoc_f1": 0.878048780487805
    },
    {
        "title": "Ad-hoc object retrieval in the web of data",
        "keywords": [
            "semantic search",
            "evaluation",
            "object retrieval"
        ],
        "abstract": "Semantic Search refers to a loose set of concepts, challenges and techniques having to do with harnessing the information of the growing Web of Data (WoD) for Web search. Here we propose a formal model of one specific semantic search task: ad-hoc object retrieval. We show that this task provides a solid framework to study some of the semantic search problems currently tackled by commercial Web search engines. We connect this task to the traditional ad-hoc document retrieval and discuss appropriate evaluation metrics. Finally, we carry out a realistic evaluation of this task in the context of a Web search application.",
        "csoc_result": [
            "semantic search",
            "search engines",
            "web searches",
            "search tasks",
            "web search engines",
            "formal model",
            "formal methods",
            "ontology",
            "online searching",
            "semantic web",
            "petri nets",
            "model checking",
            "world wide web"
        ],
        "gold_standard": [
            "web searches",
            "search engines",
            "online searching",
            "web search engines",
            "search tasks",
            "semantic search",
            "ontology",
            "semantic web"
        ],
        "skgc_topics": [
            "semantic search",
            "object retrieval",
            "web of data",
            "ad-hoc object retrieval",
            "evaluation",
            "web search",
            "document retrieval",
            "information retrieval",
            "semantic web",
            "knowledge graph",
            "linked data",
            "search engines",
            "data retrieval",
            "semantic technologies",
            "web information systems",
            "search algorithms"
        ],
        "skgc_topics_ordered": [
            "semantic search",
            "semantic web",
            "web search",
            "search engines",
            "object retrieval",
            "web of data",
            "ad-hoc object retrieval",
            "evaluation",
            "document retrieval",
            "information retrieval",
            "knowledge graph",
            "linked data",
            "data retrieval",
            "semantic technologies",
            "web information systems",
            "search algorithms"
        ],
        "gold_standard_ordered1": [
            "semantic search",
            "semantic web",
            "web search engines",
            "search engines",
            "web searches",
            "online searching",
            "search tasks",
            "ontology"
        ],
        "skgc_precision": 0.375,
        "skgc_recall": 0.75,
        "skgc_f1": 0.5,
        "csoc_topics_ordered": [
            "semantic search",
            "search engines",
            "web searches",
            "search tasks",
            "web search engines",
            "ontology",
            "online searching",
            "semantic web",
            "formal model",
            "formal methods",
            "petri nets",
            "model checking",
            "world wide web"
        ],
        "gold_standard_ordered2": [
            "semantic search",
            "search engines",
            "web searches",
            "search tasks",
            "web search engines",
            "ontology",
            "online searching",
            "semantic web"
        ],
        "csoc_precision": 0.6153846153846154,
        "csoc_recall": 1.0,
        "csoc_f1": 0.761904761904762
    },
    {
        "title": "An execution environment for C-SPARQL queries",
        "keywords": [],
        "abstract": "Continuous SPARQL (C-SPARQL) is proposed as new language for continuous queries over streams of RDF data. It covers a gap in the Semantic Web abstractions which is needed for many emerging applications, including our focus on Urban Computing. In this domain, sensor-based information on roads must be processed to deduce localized traffic conditions and then produce traffic management strategies. Executing C-SPARQL queries requires the effective integration of SPARQL and streaming technologies, which capitalize over a decade of research and development; such integration poses several nontrivial challenges.   In this paper we (a) show the syntax and semantics of the C-SPARQL language together with some examples; (b) introduce a query graph model which is an intermediate representation of queries devoted to optimization; (c) discuss the features of an execution environment that leverages existing technologies; (d) introduce optimizations in terms of rewriting rules applied to the query graph model, so as to efficiently exploit the execution environment; and (e) show evidence of the effectiveness of our optimizations on a prototype of execution environment.",
        "csoc_result": [
            "execution environments",
            "complex queries",
            "sparql",
            "program execution",
            "application execution",
            "semantic web",
            "continuous queries",
            "keyword queries",
            "languages",
            "syntactics",
            "rdf graph",
            "relational queries",
            "rdf",
            "optimization problems",
            "rdf data",
            "optimization",
            "query results",
            "query processing",
            "xquery",
            "parallel executions",
            "intermediate representations",
            "sparql queries",
            "semantics",
            "query evaluation",
            "xml",
            "computer programming languages",
            "keyword search",
            "parallel programming",
            "parallelizations",
            "linguistics",
            "parallel application",
            "operating systems",
            "object oriented programming",
            "program processors",
            "world wide web",
            "mathematics",
            "cloud computing",
            "computational linguistics",
            "search engines",
            "virtualizations",
            "program compilers",
            "correlation analysis",
            "query languages",
            "relational database",
            "resource description framework",
            "data stream",
            "virtual machines"
        ],
        "gold_standard": [
            "query results",
            "semantics",
            "query processing",
            "sparql",
            "rdf graph",
            "rdf",
            "resource description framework",
            "rdf data",
            "semantic web",
            "query languages",
            "continuous queries",
            "data stream",
            "sparql queries",
            "complex queries"
        ],
        "skgc_topics": [
            "C-SPARQL",
            "continuous queries",
            "RDF data",
            "Semantic Web",
            "Urban Computing",
            "sensor-based information",
            "traffic conditions",
            "traffic management strategies",
            "SPARQL",
            "streaming technologies",
            "query graph model",
            "optimization",
            "execution environment",
            "rewriting rules",
            "continuous query languages",
            "RDF stream processing",
            "traffic data analysis",
            "query optimization",
            "stream reasoning",
            "sensor networks",
            "real-time data processing",
            "urban traffic management",
            "semantic query processing",
            "data stream management systems",
            "query rewriting",
            "stream processing engines"
        ],
        "skgc_topics_ordered": [
            "RDF data",
            "Semantic Web",
            "continuous queries",
            "SPARQL",
            "C-SPARQL",
            "query graph model",
            "optimization",
            "execution environment",
            "rewriting rules",
            "continuous query languages",
            "RDF stream processing",
            "traffic data analysis",
            "query optimization",
            "stream reasoning",
            "sensor networks",
            "real-time data processing",
            "urban traffic management",
            "semantic query processing",
            "data stream management systems",
            "query rewriting",
            "stream processing engines",
            "Urban Computing",
            "sensor-based information",
            "traffic conditions",
            "traffic management strategies",
            "streaming technologies"
        ],
        "gold_standard_ordered1": [
            "RDF data",
            "Semantic Web",
            "continuous queries",
            "SPARQL",
            "query processing",
            "query results",
            "semantics",
            "rdf graph",
            "rdf",
            "resource description framework",
            "query languages",
            "data stream",
            "sparql queries",
            "complex queries"
        ],
        "skgc_precision": 0.3076923076923077,
        "skgc_recall": 0.5714285714285714,
        "skgc_f1": 0.4,
        "csoc_topics_ordered": [
            "query results",
            "semantics",
            "query processing",
            "sparql",
            "rdf graph",
            "rdf",
            "resource description framework",
            "rdf data",
            "semantic web",
            "query languages",
            "continuous queries",
            "data stream",
            "sparql queries",
            "complex queries",
            "execution environments",
            "program execution",
            "application execution",
            "keyword queries",
            "languages",
            "syntactics",
            "relational queries",
            "optimization problems",
            "optimization",
            "xquery",
            "parallel executions",
            "intermediate representations",
            "query evaluation",
            "xml",
            "computer programming languages",
            "keyword search",
            "parallel programming",
            "parallelizations",
            "linguistics",
            "parallel application",
            "operating systems",
            "object oriented programming",
            "program processors",
            "world wide web",
            "mathematics",
            "cloud computing",
            "computational linguistics",
            "search engines",
            "virtualizations",
            "program compilers",
            "correlation analysis",
            "relational database",
            "virtual machines"
        ],
        "gold_standard_ordered2": [
            "query results",
            "semantics",
            "query processing",
            "sparql",
            "rdf graph",
            "rdf",
            "resource description framework",
            "rdf data",
            "semantic web",
            "query languages",
            "continuous queries",
            "data stream",
            "sparql queries",
            "complex queries"
        ],
        "csoc_precision": 0.2978723404255319,
        "csoc_recall": 1.0,
        "csoc_f1": 0.45901639344262296
    }
]